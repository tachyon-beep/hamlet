# Level 2: Partial Observability (POMDP)
#
# See docs/TRAINING_LEVELS.md for complete specification.
#
# Key features:
# - Agent sees only 5×5 local window (partial observability)
# - RecurrentSpatialQNetwork with LSTM memory
# - Must build mental map through exploration
# - Target network for temporal credit assignment (ACTION #9)
# - NO proximity shaping (must learn through interaction)
# - Sparse rewards (milestone bonuses only)
#
# Expected performance:
# - 3000-5000 episodes to learn (vs 1000-2000 for Level 1)
# - Peak survival: 150-250 steps (vs 250-350 for Level 1)
# - 30-40% of time spent exploring
# - Realistic cognitive behavior (memory, mistakes, getting lost)

# Environment configuration
environment:
  grid_size: 8  # 8×8 grid world
  partial_observability: true  # LEVEL 2: Agent sees only 5×5 local window
  vision_range: 2  # 5×5 window (2*2+1)

# Population configuration
population:
  num_agents: 1  # Single agent for now
  learning_rate: 0.0001  # Lower LR for recurrent networks (more stable)
  gamma: 0.99
  replay_buffer_capacity: 10000
  network_type: recurrent  # NEW: RecurrentSpatialQNetwork with LSTM

# Curriculum configuration (adversarial difficulty adjustment)
curriculum:
  max_steps_per_episode: 500
  survival_advance_threshold: 0.7  # Advance to next stage if 70% survival
  survival_retreat_threshold: 0.3  # Retreat if <30% survival
  entropy_gate: 0.5  # Minimum policy entropy to advance
  min_steps_at_stage: 1000  # Min episodes before stage change

# Exploration configuration (RND + adaptive annealing)
exploration:
  embed_dim: 128
  initial_intrinsic_weight: 0.1  # Much lower - let extrinsic milestones drive learning
  variance_threshold: 100.0  # Fixed: increased from 10.0 to prevent premature annealing
  survival_window: 100  # Track last 100 episodes for annealing
  epsilon_start: 1.0
  epsilon_min: 0.01
  epsilon_decay: 0.999  # Slow decay for thorough exploration

# Training configuration
training:
  device: cuda  # Use GPU if available
  max_episodes: 10000  # Total episodes for this training run
