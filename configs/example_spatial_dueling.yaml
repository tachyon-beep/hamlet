# Hamlet Training Configuration - Spatial Dueling DQN with Shaped Rewards
# This configuration demonstrates the most advanced architecture and reward system

experiment:
  name: hamlet_spatial_dueling_shaped
  description: "Spatial Dueling DQN with hybrid reward shaping (Tier 1 + Tier 2)"
  tracking_uri: "mlruns"

environment:
  grid_width: 8
  grid_height: 8
  initial_energy: 100.0
  initial_hygiene: 100.0
  initial_satiation: 100.0
  initial_money: 50.0
  energy_depletion: 0.5
  hygiene_depletion: 0.3
  satiation_depletion: 0.4
  affordance_positions:
    Bed: [1, 1]
    Shower: [6, 1]
    HomeMeal: [1, 6]
    FastFood: [5, 6]
    Job: [6, 6]
    Gym: [7, 3]
    Bar: [7, 0]
    Recreation: [0, 7]

agents:
  - agent_id: agent_0
    algorithm: dqn
    state_dim: 72
    action_dim: 5
    learning_rate: 0.00025  # Atari DQN standard (reduced from 0.001)
    gamma: 0.99
    epsilon: 1.0
    epsilon_min: 0.01
    epsilon_decay: 0.995
    device: auto
    network_type: spatial_dueling  # Best of both worlds: CNN + dueling
    grid_size: 8

training:
  num_episodes: 1000
  max_steps_per_episode: 500
  batch_size: 64
  learning_starts: 1000
  target_update_frequency: 100
  replay_buffer_size: 10000
  save_frequency: 100
  checkpoint_dir: "checkpoints_spatial_dueling/"
  log_frequency: 10

metrics:
  tensorboard: true
  tensorboard_dir: "runs_spatial_dueling"
  database: true
  database_path: "metrics_spatial_dueling.db"
  replay_storage: false  # Disable to save disk space
  replay_dir: "replays"
  replay_sample_rate: 0.1
  live_broadcast: false
