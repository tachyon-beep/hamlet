# P1.1: Full-Fidelity Checkpointing - TDD Implementation Plan

**Status:** ðŸ”„ IN PROGRESS  
**Date Started:** November 2, 2025  
**Approach:** Strict Test-Driven Development

---

## Current State Analysis

### What's Already Done âœ…

**Population Level (`population/vectorized.py`):**

- âœ… `get_checkpoint_state()` exists (line 626)
  - Saves: version, q_network, optimizer, total_steps, exploration_state
  - Saves: target_network (if recurrent), training_step_counter
  - Saves: replay_buffer (serialized)
- âœ… `load_checkpoint_state()` exists (line 664)
  - Restores all of the above

**Runner Level (`demo/runner.py`):**

- âœ… `save_checkpoint()` exists (line 93)
  - Saves: episode, timestamp
  - Saves: population_state (partial - only q_network + optimizer)
  - Saves: exploration_state (partial)
  - Saves: epsilon (for display)
- âœ… `load_checkpoint()` exists (line 124)
  - Restores: episode
  - Restores: q_network, optimizer
  - Restores: exploration_state

### What's Missing âŒ

**Gap 1: Runner not using Population's full checkpoint**

- Runner saves partial state manually
- Population's `get_checkpoint_state()` has MORE data
- **Fix:** Wire `population.get_checkpoint_state()` into runner

**Gap 2: Curriculum state not saved**

- Curriculum has `state_dict()` method (line 338 of adversarial.py)
- Runner doesn't call it
- **Fix:** Add curriculum_state to checkpoint

**Gap 3: Affordance layout not saved**

- Environment has `get_affordance_positions()` method
- Runner doesn't call it
- **Fix:** Add affordance_layout to checkpoint

**Gap 4: No flush before checkpoint (P1.2 Gap 3.2)**

- Episode accumulators not flushed before save
- Could lose in-progress episode data
- **Fix:** Call `flush_episode()` for all agents before save

**Gap 5: Curriculum not restored in load**

- Runner doesn't restore curriculum state
- Agents restart from stage 1
- **Fix:** Call `curriculum.load_state_dict()` in load

**Gap 6: Affordance layout not restored**

- Environment positions randomized on restart
- Breaks checkpoint continuity
- **Fix:** Call `env.set_affordance_positions()` in load

---

## TDD Implementation Strategy

### Phase 1: Test Current State (GREEN Baseline)

**Goal:** Verify what works today

1. Test `population.get_checkpoint_state()` returns expected keys
2. Test `population.load_checkpoint_state()` restores Q-network
3. Test runner saves/loads episode number
4. Test replay buffer serialization roundtrip

**Estimated Time:** 30 minutes

### Phase 2: Wire Population's Full Checkpoint (REDâ†’GREEN)

**Goal:** Use population's complete state instead of manual partial save

**Test 1:** Runner checkpoint should include all population fields

- Assert: checkpoint["population_state"] has version, replay_buffer, target_network

**Implementation:**

```python
# In runner.save_checkpoint() - replace manual dict with:
checkpoint["population_state"] = self.population.get_checkpoint_state()
```

**Test 2:** Runner load should restore full population state

- Create population, train 10 steps, save, load, verify replay buffer size matches

**Implementation:**

```python
# In runner.load_checkpoint() - replace manual loads with:
self.population.load_checkpoint_state(checkpoint["population_state"])
```

**Estimated Time:** 45 minutes

### Phase 3: Add Curriculum State (REDâ†’GREEN)

**Test 1:** Checkpoint should include curriculum tracker state

- Advance curriculum to stage 3, save, verify checkpoint["curriculum_state"] exists

**Implementation:**

```python
# In runner.save_checkpoint():
checkpoint["curriculum_state"] = self.curriculum.state_dict()
```

**Test 2:** Curriculum stage should survive save/load

- Advance to stage 3, save, load new runner, verify stage==3

**Implementation:**

```python
# In runner.load_checkpoint():
if "curriculum_state" in checkpoint:
    self.curriculum.load_state_dict(checkpoint["curriculum_state"])
```

**Estimated Time:** 30 minutes

### Phase 4: Add Affordance Layout (REDâ†’GREEN)

**Test 1:** Checkpoint should include affordance positions

- Save checkpoint, verify checkpoint["affordance_layout"] exists

**Implementation:**

```python
# In runner.save_checkpoint():
checkpoint["affordance_layout"] = self.env.get_affordance_positions()
```

**Test 2:** Affordance positions should be identical after restore

- Get original positions, save, load new runner, verify positions match

**Implementation:**

```python
# In runner.load_checkpoint():
if "affordance_layout" in checkpoint:
    self.env.set_affordance_positions(checkpoint["affordance_layout"])
```

**Estimated Time:** 30 minutes

### Phase 5: Add Flush-Before-Checkpoint (REDâ†’GREEN)

**Test 1:** Episode accumulators should be empty after save

- Accumulate partial episode (5 steps), save, verify accumulators cleared

**Implementation:**

```python
# In runner.save_checkpoint() - BEFORE creating checkpoint dict:
if self.population.is_recurrent:
    for agent_idx in range(self.population.num_agents):
        self.population.flush_episode(agent_idx=agent_idx, synthetic_done=True)
```

**Test 2:** Replay buffer should contain flushed data

- Accumulate 5 steps, save, verify replay buffer size increased by 1 episode

**Estimated Time:** 30 minutes

### Phase 6: Multi-Agent Preparation (REDâ†’GREEN)

**Test 1:** Checkpoint should save agent_ids

- Create 3-agent population, save, verify checkpoint["agent_ids"] == ["agent_0", "agent_1", "agent_2"]

**Implementation:**

```python
# In population.get_checkpoint_state():
checkpoint["agent_ids"] = self.agent_ids
```

**Test 2:** Multi-agent curriculum state should work

- 3 agents, advance each to different stages, save, load, verify all stages preserved

**Estimated Time:** 30 minutes

---

## Total Estimated Time: 3 hours

**Breakdown:**

- Phase 1 (Baseline): 30 min
- Phase 2 (Full Population): 45 min
- Phase 3 (Curriculum): 30 min
- Phase 4 (Affordances): 30 min
- Phase 5 (Flush): 30 min
- Phase 6 (Multi-Agent): 30 min
- **Buffer:** 15 min

---

## Success Criteria

After completing all phases:

âœ… **Checkpoint Version:** >= 2  
âœ… **Population State:** Q-network, optimizer, replay buffer, exploration, target network  
âœ… **Curriculum State:** Agent stages, performance trackers  
âœ… **Affordance Layout:** All positions preserved  
âœ… **Episode Flush:** No data loss on checkpoint save  
âœ… **Multi-Agent Ready:** Agent IDs stored, curriculum per-agent  
âœ… **File Integrity:** Save/load cycle preserves all data  

---

## Next Steps

1. Create `tests/test_townlet/test_p1_1_checkpoint_phase1.py` (baseline tests)
2. Run tests â†’ ALL GREEN (current state works)
3. Create phase 2 tests â†’ RED (missing features)
4. Implement phase 2 â†’ GREEN
5. Repeat for phases 3-6

---

**Report Status:** READY FOR IMPLEMENTATION  
**Confidence:** High (95%) - all APIs already exist, just need wiring
