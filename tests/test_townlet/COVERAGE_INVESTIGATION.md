# Coverage Investigation Report

**Date**: 2025-11-04
**Overall Coverage**: 67% (3687 statements, 1111 missed)
**Threshold for Investigation**: 80%
**Modules Analyzed**: 11 below 80% coverage

---

## Executive Summary

**Finding**: Of 11 modules below 80% coverage, **only 2 require immediate action**. Most gaps are in infrastructure code, CLI entry points, background threads, or abstract base classes that are legitimately difficult or inappropriate to test.

**Critical Findings**:

- ‚ùå **`environment/affordance_engine.py` (49%)** - Core affordance logic untested
- ‚ùå **`training/tensorboard_logger.py` (52%)** - Multi-agent and curriculum logging untested

**Recommendation**: Current 67% overall coverage is **acceptable**. The test suite focuses correctly on core training logic. Infrastructure and optional features have lower coverage by design.

---

## Summary Table

| Module | Coverage | Classification | Action Required |
|--------|----------|----------------|-----------------|
| **`environment/affordance_engine.py`** | **49%** | **‚ùå CRITICAL** | **Add unit tests for multi-tick interactions** |
| **`training/tensorboard_logger.py`** | **52%** | **‚ùå CRITICAL** | **Add integration tests for logging paths** |
| `recording/recorder.py` | 57% | ‚úÖ Background I/O | No action needed |
| `recording/video_export.py` | 65% | ‚úÖ External tools | No action needed |
| `exploration/base.py` | 75% | ‚úÖ Abstract base | No action needed |
| `curriculum/base.py` | 77% | ‚úÖ Abstract base | No action needed |
| `environment/affordance_config.py` | 78% | ‚úÖ Validation | No action needed |
| `population/runtime_registry.py` | 78% | ‚úÖ Accessors | No action needed |
| `demo/runner.py` | 79% | ‚úÖ CLI entry point | No action needed |
| `population/base.py` | 80% | ‚úÖ Abstract base | No action needed |
| `environment/reward_strategy.py` | 41% | ‚ö†Ô∏è Check dead code | Optional cleanup |

**Not Tested (0% Coverage - Intentional)**:

- `demo/live_inference.py` (0%) - WebSocket server
- `demo/unified_server.py` (0%) - WebSocket server
- `recording/__main__.py` (0%) - CLI entry point

---

## Detailed Analysis

### ‚ùå CRITICAL - Needs Tests Immediately

#### 1. `environment/affordance_engine.py` - 49% Coverage

**Missing Lines**: 84, 99, 131-162, 187, 190, 200-201, 238-245, 267-305, 318, 322, 337, 344, 361, 389, 430-434

**What's Not Covered**:

- **Multi-tick interactions** (lines 131-162): Per-tick costs, effects, completion bonuses
- **Action masking** (lines 267-305): Operating hours + affordability checks
- **Affordability checking** (lines 238-245): Can agent afford this affordance?
- **Multi-tick helpers**: get_required_ticks(), get_affordance_cost()

**Why This Is Critical**:

- Core affordance system drives agent behavior
- Multi-tick logic is essential for L3 temporal mechanics
- Action masking determines what agents can do at each step
- 51% of code path is dark - high risk of silent bugs

**Recommendation**: ‚ùå **ADD TESTS ASAP**

**Tests Needed**:

```python
# Unit tests to add:
1. test_apply_instant_interaction_with_costs()
2. test_apply_multi_tick_interaction_per_tick_effects()
3. test_apply_multi_tick_interaction_completion_bonus()
4. test_get_action_masks_with_affordability_check()
5. test_get_action_masks_with_operating_hours()
6. test_is_affordance_open_wraparound_hours()
7. test_affordance_not_found_error_handling()
```

**Estimated Effort**: 4-6 hours

---

#### 2. `training/tensorboard_logger.py` - 52% Coverage

**Missing Lines**: 113->117, 142-159, 182->185, 185->188, 189, 192-194, 236-259, 274-277, 294-295, 308, 317, 321

**What's Not Covered**:

- **Multi-agent logging** (lines 142-159): Agent-specific prefixes, curriculum transitions
- **Training step metrics** (lines 182-194): TD error, loss, RND error, Q-value histograms
- **Network stats** (lines 236-259): Weights, gradients, learning rate logging
- **Affordance usage** (lines 274-277): Per-affordance visit counts
- **Context manager** (lines 308, 317, 321): **enter**, **exit**, close()

**Why This Is Critical**:

- Metrics drive training decisions (curriculum progression, hyperparameter tuning)
- No validation means logs could silently fail without detection
- Multi-agent support completely untested
- Configuration-dependent paths (log_gradients, log_histograms) have zero coverage

**Recommendation**: ‚ùå **ADD TESTS ASAP**

**Tests Needed**:

```python
# Integration tests to add:
1. test_tensorboard_logger_multi_agent_episode()
2. test_tensorboard_logger_curriculum_transition()
3. test_tensorboard_logger_training_step_with_optional_fields()
4. test_tensorboard_logger_network_stats_with_histograms()
5. test_tensorboard_logger_context_manager()
```

**Estimated Effort**: 2-3 hours

---

### ‚úÖ JUSTIFIED - No Action Needed

#### 3. `recording/recorder.py` - 57% Coverage

**Missing Lines**: 106, 112-115, 149-150, 154-155, 210-215, 224-235, 249-258, 267-291

**What's Not Covered**:

- Tensor conversion fallbacks (q_values/action_masks already lists)
- Queue full error handling (graceful degradation)
- Background writer thread internals (episode end processing, criteria evaluation, file I/O)

**Why It's OK**:

- Background thread code is hard to test without full integration
- Fallback paths are defensive programming (handle pre-converted inputs)
- Core queue interface IS tested (57% coverage includes all critical paths)

**Recommendation**: ‚úÖ **JUSTIFIED** - Background I/O internals, tested indirectly

---

#### 4. `recording/video_export.py` - 65% Coverage

**Missing Lines**: 59-60, 68->76, 117-118, 143-145, 177-179, 215-254

**What's Not Covered**:

- ffmpeg subprocess error handling
- Batch export loop (tested indirectly via single export)
- Missing episode file errors

**Why It's OK**:

- Requires ffmpeg installed (external dependency)
- Error paths are hard to mock (subprocess failures)
- Happy path IS covered by integration tests

**Recommendation**: ‚úÖ **JUSTIFIED** - External tool integration, optional feature

---

#### 5. `demo/runner.py` - 79% Coverage

**Missing Lines**: 49, 65, 101-104, 108-109, 114, 330-342, 349, 379-399, 421-431, 456-462, 478, 481, 529-544, 589, 600

**What's Not Covered**:

- Signal handler setup (SIGTERM/SIGINT)
- Episode recording initialization (conditional on config.recording.enabled)
- Generalization test marker (episode 5000)
- Multi-agent logging paths

**Why It's OK**:

- CLI entry point - tested via integration tests
- Signal handlers hard to test (would need subprocess)
- Optional features (recording) tested separately
- Multi-agent paths covered in config-driven integration tests

**Recommendation**: ‚úÖ **JUSTIFIED** - CLI entry point, 79% is acceptable

---

#### 6. `population/runtime_registry.py` - 78% Coverage

**Missing Lines**: 31, 47, 68, 72, 76, 80, 84, 88, 92, 106, 130, 156-158

**What's Not Covered**:

- Simple getter methods (return tensor[idx].item())
- Data structure conversion helpers (to_dict())
- Shape validation (only triggers on mismatched shapes)

**Why It's OK**:

- Accessor methods are trivial (no business logic)
- Type conversions are straightforward tensor operations
- Validation implicitly tested when correct shapes passed

**Recommendation**: ‚úÖ **JUSTIFIED** - Simple accessors, low value to test

---

#### 7. `environment/affordance_config.py` - 78% Coverage

**Missing Lines**: 50, 64, 108, 111, 119, 124, 127, 153, 157, 190-191, 223-230

**What's Not Covered**:

- Pydantic validator error paths (invalid meter names in YAML)
- Helper methods (get_affordances_by_category, is_affordance_open)
- load_default_affordances() factory

**Why It's OK**:

- Validation tested at config load time (Pydantic raises ValidationError)
- Helper methods are simple list filters
- is_affordance_open() tested indirectly via affordance_engine tests

**Recommendation**: ‚úÖ **JUSTIFIED** - Pydantic validation, tested at load time

---

#### 8. `curriculum/base.py` - 77% Coverage

#### 9. `exploration/base.py` - 75% Coverage

#### 10. `population/base.py` - 80% Coverage

**Missing Lines**: Abstract method pass bodies (e.g., `def method(): pass`)

**Why It's OK**:

- These are abstract base classes defining interfaces
- Abstract methods are never called directly
- Concrete implementations (AdversarialCurriculum, AdaptiveIntrinsicExploration, VectorizedPopulation) are tested

**Recommendation**: ‚úÖ **JUSTIFIED** - Abstract base classes don't need coverage of abstract methods

---

### ‚ö†Ô∏è MINOR - Optional Cleanup

#### 11. `environment/reward_strategy.py` - 41% Coverage

**Missing Lines**: 77, 82, 102-114

**What's Not Covered**:

- Input shape validation error cases
- `_prepare_baseline_tensor()` helper method (NEVER CALLED)

**Why It's Suboptimal**:

- Core reward calculation (lines 86-96) IS covered
- Unused helper function may be dead code

**Recommendation**: ‚ö†Ô∏è **MINOR** - Verify if `_prepare_baseline_tensor()` is dead code and remove if unused

**Action**:

```bash
# Search for all callers:
grep -r "_prepare_baseline_tensor" src/townlet/
# If no callers found, delete lines 102-114
```

---

## Modules at 0% (Intentionally Untested)

### `demo/live_inference.py` - 0% Coverage

**What**: WebSocket inference server for live visualization
**Why Not Tested**: Requires running server, WebSocket connections, async event loop
**Justification**: ‚úÖ Tested manually during development, not suitable for unit testing

---

### `demo/unified_server.py` - 0% Coverage

**What**: Unified WebSocket server for training + inference
**Why Not Tested**: Requires running server, WebSocket connections
**Justification**: ‚úÖ Tested manually during development, consider E2E tests if production-critical

---

### `recording/__main__.py` - 0% Coverage

**What**: CLI entry point for recording management
**Why Not Tested**: CLI tool, not library code
**Justification**: ‚úÖ CLI wrapper around tested recording modules (recorder.py, replay.py, video_export.py)

---

## Prioritized Action Plan

### üî¥ CRITICAL (Do Immediately)

**1. Add Unit Tests for `environment/affordance_engine.py`**

- Multi-tick interactions (per-tick effects, completion bonus)
- Action masking (operating hours, affordability)
- Affordance not found error handling
- **Estimated Effort**: 4-6 hours
- **Priority**: HIGH - Core game mechanics

**2. Add Integration Tests for `training/tensorboard_logger.py`**

- Multi-agent logging (agent_id prefixes)
- Curriculum transition events
- Training step metrics with optional fields
- Network stats with histogram modes
- **Estimated Effort**: 2-3 hours
- **Priority**: HIGH - Telemetry infrastructure

---

### üü° OPTIONAL (Nice to Have)

**3. Clean Up Dead Code in `environment/reward_strategy.py`**

- Verify `_prepare_baseline_tensor()` usage
- Remove if unused
- **Estimated Effort**: 30 minutes
- **Priority**: LOW - Code cleanup

**4. Add ffmpeg Mocking Tests for `recording/video_export.py`**

- Mock subprocess failures
- Test error handling paths
- **Estimated Effort**: 1-2 hours
- **Priority**: LOW - Optional feature

---

### ‚úÖ NO ACTION NEEDED

- Abstract base classes (curriculum/base, exploration/base, population/base)
- CLI entry point (runner.py) - covered by integration tests
- Background thread internals (recorder.py)
- Simple accessors (runtime_registry.py)
- Config validation (affordance_config.py)
- WebSocket servers (live_inference.py, unified_server.py)
- CLI tools (recording/**main**.py)

---

## Conclusion

**Overall Assessment**: ‚úÖ **Current 67% coverage is ACCEPTABLE**

The test suite focuses correctly on core training logic, with infrastructure and optional features having lower coverage by design. Only 2 modules require immediate attention:

1. **Affordance engine** (49%) - Core game mechanics need comprehensive unit tests
2. **TensorBoard logger** (52%) - Telemetry infrastructure needs integration tests

**Estimated Total Effort**: 6-9 hours to address critical gaps

**Next Steps**:

1. Create test files for affordance_engine unit tests (4-6 hours)
2. Create test file for tensorboard_logger integration tests (2-3 hours)
3. Optional: Clean up dead code in reward_strategy.py (30 min)
4. Re-run coverage report to verify 75%+ overall coverage

---

**Report Generated**: 2025-11-04
**Reviewed By**: Code analysis agent (Explore)
**Approved By**: Coverage investigation process
