# Config v2.1 Implementation Plan: Phases 4-7

**Date**: 2025-11-15
**Status**: Ready for execution
**Prerequisites**: Phases 1-3 complete (see `2025-11-15-config-v2.1-phases-1-3.md`)

This document provides bite-sized, executable tasks for Phases 4-7 of the config v2.1 implementation.

## Phase 4: Compiler Updates (2-3 hours)

**Objective**: Update `compiler.py` to load hierarchical v2.1 structure and validate cross-curriculum consistency.

**Success Criteria**:
- Compiler loads all 9 config files from hierarchical structure
- Cross-curriculum vocabulary validation enforced
- Observation spec uses Support/Active pattern
- L1 config compiles successfully

### Task 4.1: Update compiler.py function signature

**Files:**
- Edit: `src/townlet/universe/compiler.py`

**Step 1: Read current compiler function**
```bash
python3 << 'PYTEST'
from pathlib import Path
import inspect
from townlet.universe.compiler import compile_universe

# Print current signature
sig = inspect.signature(compile_universe)
print(f"Current signature: compile_universe{sig}")

# Print first 20 lines of function
source_lines = inspect.getsource(compile_universe).split('\n')[:20]
print("\nFirst 20 lines:")
for i, line in enumerate(source_lines, 1):
    print(f"{i:3}: {line}")
PYTEST
```

**Expected Output**: Shows current signature (likely `config_dir: Path`)

**Step 2: Update function signature and docstring**

Find the function definition in `compiler.py` and update:

```python
def compile_universe(experiment_dir: Path) -> CompiledUniverse:
    """
    Compile hierarchical config v2.1 structure into a CompiledUniverse.

    Expected directory structure:
        experiment_dir/
        â”œâ”€â”€ experiment.yaml
        â”œâ”€â”€ stratum.yaml
        â”œâ”€â”€ environment.yaml
        â”œâ”€â”€ actions.yaml
        â”œâ”€â”€ agent.yaml
        â””â”€â”€ levels/
            â”œâ”€â”€ L1_full_observability/
            â”‚   â”œâ”€â”€ curriculum.yaml
            â”‚   â”œâ”€â”€ bars.yaml
            â”‚   â”œâ”€â”€ affordances.yaml
            â”‚   â””â”€â”€ training.yaml
            â””â”€â”€ L2_partial_observability/
                â””â”€â”€ ...

    Args:
        experiment_dir: Path to experiment root directory

    Returns:
        CompiledUniverse with validated, cross-curriculum consistent configuration

    Raises:
        ValueError: If vocabulary inconsistent across curriculum levels
        FileNotFoundError: If required config files missing
    """
```

**Step 3: Commit signature change**
```bash
git add src/townlet/universe/compiler.py
git commit -m "refactor(compiler): update signature for v2.1 hierarchical structure

BREAKING CHANGE: compile_universe now expects hierarchical experiment_dir

Old: compile_universe(config_dir) where config_dir contains flat *.yaml files
New: compile_universe(experiment_dir) where experiment_dir contains layered structure"
```

### Task 4.2: Implement Stage 1 - Load hierarchical structure

**Files:**
- Edit: `src/townlet/universe/compiler.py`

**Step 1: Add helper function to load experiment structure**

Add this function before `compile_universe`:

```python
def _load_experiment_structure(experiment_dir: Path) -> tuple:
    """
    Load all config files from hierarchical v2.1 structure.

    Returns:
        (experiment, stratum, environment, actions, agent, levels_dict)
        where levels_dict = {"L1_full_observability": (curriculum, bars, affordances, training), ...}
    """
    from townlet.config.experiment_config import ExperimentConfig
    from townlet.config.stratum_config import StratumConfig
    from townlet.config.environment_config import EnvironmentConfig
    from townlet.config.actions_config import ActionsConfig
    from townlet.config.agent_config import AgentConfig
    from townlet.config.curriculum_config import CurriculumConfig
    from townlet.config.bars_config import BarsConfig  # existing
    from townlet.config.affordances_config import AffordancesConfig  # existing
    from townlet.config.training_config import TrainingConfig  # existing

    # Load shared configs
    experiment = ExperimentConfig.from_yaml(experiment_dir / "experiment.yaml")
    stratum = StratumConfig.from_yaml(experiment_dir / "stratum.yaml")
    environment = EnvironmentConfig.from_yaml(experiment_dir / "environment.yaml")
    actions = ActionsConfig.from_yaml(experiment_dir / "actions.yaml")
    agent = AgentConfig.from_yaml(experiment_dir / "agent.yaml")

    # Load all curriculum levels
    levels_dir = experiment_dir / "levels"
    if not levels_dir.exists():
        raise FileNotFoundError(f"Missing levels/ directory in {experiment_dir}")

    levels_dict = {}
    for level_dir in sorted(levels_dir.iterdir()):
        if not level_dir.is_dir():
            continue

        curriculum = CurriculumConfig.from_yaml(level_dir / "curriculum.yaml")
        bars = BarsConfig.from_yaml(level_dir / "bars.yaml")
        affordances = AffordancesConfig.from_yaml(level_dir / "affordances.yaml")
        training = TrainingConfig.from_yaml(level_dir / "training.yaml")

        levels_dict[level_dir.name] = (curriculum, bars, affordances, training)

    if not levels_dict:
        raise ValueError(f"No curriculum levels found in {levels_dir}")

    return (experiment, stratum, environment, actions, agent, levels_dict)
```

**Step 2: Update compile_universe to use new loader**

Replace the beginning of `compile_universe` with:

```python
def compile_universe(experiment_dir: Path) -> CompiledUniverse:
    """[docstring from Task 4.1]"""

    # Stage 1: Load hierarchical structure
    (experiment, stratum, environment, actions, agent, levels_dict) = _load_experiment_structure(experiment_dir)

    print(f"Loaded experiment: {experiment.metadata.name}")
    print(f"  Stratum: {stratum.substrate.substrate_type}")
    print(f"  Environment: {len(environment.meters.meters)} meters, {len(environment.affordances.affordances)} affordances")
    print(f"  Curriculum levels: {list(levels_dict.keys())}")

    # [Continue with rest of compilation stages...]
```

**Step 3: Test Stage 1 loads configs**
```bash
export PYTHONPATH=$(pwd)/src:$PYTHONPATH
python3 << 'PYTEST'
from pathlib import Path
from townlet.universe.compiler import _load_experiment_structure

experiment_dir = Path("configs/default_curriculum")
(experiment, stratum, environment, actions, agent, levels_dict) = _load_experiment_structure(experiment_dir)

print(f"âœ“ Experiment: {experiment.metadata.name}")
print(f"âœ“ Stratum: {stratum.substrate.substrate_type}")
print(f"âœ“ Environment: {len(environment.meters.meters)} meters")
print(f"âœ“ Levels: {list(levels_dict.keys())}")

assert experiment.metadata.name == "Default Curriculum"
assert stratum.substrate.substrate_type == "grid"
assert "L1_full_observability" in levels_dict
print("\nSUCCESS: Stage 1 loading working")
PYTEST
```

**Step 4: Commit Stage 1**
```bash
git add src/townlet/universe/compiler.py
git commit -m "feat(compiler): implement Stage 1 - load hierarchical v2.1 structure

- Add _load_experiment_structure() helper
- Loads 5 shared configs + all curriculum levels
- Returns structured tuple for validation stages"
```

### Task 4.3: Implement Stage 2 - Cross-curriculum vocabulary validation

**Files:**
- Edit: `src/townlet/universe/compiler.py`

**Step 1: Add vocabulary validation helper**

Add this function before `compile_universe`:

```python
def _validate_vocabulary_consistency(environment: EnvironmentConfig, levels_dict: dict) -> None:
    """
    Validate that all curriculum levels use the same vocabulary as environment.yaml.

    Enforces the WHAT vs HOW split:
    - environment.yaml defines WHAT exists (vocabulary - breaks checkpoints)
    - levels/*/bars.yaml defines HOW bars behave (parameters - doesn't break)

    Raises:
        ValueError: If any level has different meter/affordance vocabulary
    """
    # Get vocabulary from environment.yaml
    env_meters = set(m.name for m in environment.meters.meters)
    env_affordances = set(a.name for a in environment.affordances.affordances)

    # Check each curriculum level
    for level_name, (curriculum, bars, affordances, training) in levels_dict.items():
        # Check meter vocabulary
        level_meters = set(b.name for b in bars.bars)
        if level_meters != env_meters:
            missing = env_meters - level_meters
            extra = level_meters - env_meters
            msg = f"Vocabulary mismatch in {level_name}/bars.yaml:\n"
            if missing:
                msg += f"  Missing meters: {sorted(missing)}\n"
            if extra:
                msg += f"  Extra meters: {sorted(extra)}\n"
            msg += f"All levels must have same meters as environment.yaml"
            raise ValueError(msg)

        # Check affordance vocabulary
        level_affordances = set(a.name for a in affordances.affordances)
        if level_affordances != env_affordances:
            missing = env_affordances - level_affordances
            extra = level_affordances - env_affordances
            msg = f"Vocabulary mismatch in {level_name}/affordances.yaml:\n"
            if missing:
                msg += f"  Missing affordances: {sorted(missing)}\n"
            if extra:
                msg += f"  Extra affordances: {sorted(extra)}\n"
            msg += f"All levels must have same affordances as environment.yaml"
            raise ValueError(msg)

    print(f"âœ“ Vocabulary consistent across {len(levels_dict)} curriculum levels")
    print(f"  {len(env_meters)} meters: {sorted(env_meters)}")
    print(f"  {len(env_affordances)} affordances: {sorted(env_affordances)}")
```

**Step 2: Call validator in compile_universe**

Add after Stage 1:

```python
def compile_universe(experiment_dir: Path) -> CompiledUniverse:
    """[docstring]"""

    # Stage 1: Load hierarchical structure
    (experiment, stratum, environment, actions, agent, levels_dict) = _load_experiment_structure(experiment_dir)

    # Stage 2: Cross-curriculum vocabulary validation
    _validate_vocabulary_consistency(environment, levels_dict)

    # [Continue with rest of compilation...]
```

**Step 3: Test vocabulary validation**
```bash
export PYTHONPATH=$(pwd)/src:$PYTHONPATH
python3 << 'PYTEST'
from pathlib import Path
from townlet.universe.compiler import _load_experiment_structure, _validate_vocabulary_consistency

experiment_dir = Path("configs/default_curriculum")
(experiment, stratum, environment, actions, agent, levels_dict) = _load_experiment_structure(experiment_dir)

# Should pass (same vocabulary)
_validate_vocabulary_consistency(environment, levels_dict)
print("SUCCESS: Vocabulary validation working")
PYTEST
```

**Step 4: Commit Stage 2**
```bash
git add src/townlet/universe/compiler.py
git commit -m "feat(compiler): implement Stage 2 - vocabulary validation

- Add _validate_vocabulary_consistency() helper
- Enforces WHAT vs HOW split (vocabulary must match environment.yaml)
- Raises clear errors showing missing/extra meters or affordances"
```

### Task 4.4: Implement Stage 5 - Observation spec with Support/Active pattern

**Files:**
- Edit: `src/townlet/universe/compiler.py`

**Step 1: Add observation spec builder with Support/Active pattern**

Add this function before `compile_universe`:

```python
def _build_observation_spec(stratum: StratumConfig, environment: EnvironmentConfig,
                           curriculum: CurriculumConfig, agent: AgentConfig) -> ObservationSpec:
    """
    Build observation spec using Support/Active pattern.

    Support (stratum): Which fields CAN exist (declared at experiment level)
    Active (curriculum): Which fields ARE active vs masked (per curriculum level)

    This enables:
    - Transfer learning: All levels have same obs_dim (L1=L2=121)
    - Power user optimization: Future observation_policy can exclude unused fields
    """
    from townlet.vfs.observation_builder import ObservationField

    fields = []
    offset = 0

    # Vision fields (Support/Active pattern)
    if stratum.vision.support in ["both", "global"]:
        # Grid encoding supported, check if active this level
        is_active = (curriculum.active_vision == "global")
        grid_dims = _compute_grid_encoding_dims(stratum.substrate)

        fields.append(ObservationField(
            name="obs_grid_encoding",
            start_index=offset,
            end_index=offset + grid_dims,
            dims=grid_dims,
            curriculum_active=is_active,
            description="Full grid one-hot encoding" if is_active else "Masked (inactive this level)"
        ))
        offset += grid_dims

    if stratum.vision.support in ["both", "partial"]:
        # Local window supported, check if active this level
        is_active = (curriculum.active_vision == "partial")

        # Compute local window size from normalized vision_range
        grid_size = stratum.substrate.grid.size  # e.g., 8
        window_radius = int(curriculum.vision_range * grid_size)  # e.g., 0.625 * 8 = 5
        window_dims = (2 * window_radius + 1) ** 2  # e.g., 11Ã—11 = 121... wait, this seems wrong

        # Actually, let's use the reference calculation
        # For L2: vision_range=0.625, grid_size=8 â†’ radius=5, but window is 5Ã—5 not 11Ã—11
        # So vision_range=0.625 means "5 cells out of 8" which is the window SIZE not radius
        window_size = max(3, int(curriculum.vision_range * grid_size))  # minimum 3Ã—3
        if window_size % 2 == 0:  # force odd
            window_size += 1
        window_dims = window_size ** 2

        fields.append(ObservationField(
            name="obs_local_window",
            start_index=offset,
            end_index=offset + window_dims,
            dims=window_dims,
            curriculum_active=is_active,
            description=f"{window_size}Ã—{window_size} local window" if is_active else "Masked (inactive this level)"
        ))
        offset += window_dims

    # Position (always active)
    position_dims = stratum.substrate.grid.dimensions  # 2 for Grid2D
    fields.append(ObservationField(
        name="obs_position",
        start_index=offset,
        end_index=offset + position_dims,
        dims=position_dims,
        curriculum_active=True,
        description="Agent position coordinates"
    ))
    offset += position_dims

    # Velocity (always active)
    fields.append(ObservationField(
        name="obs_velocity",
        start_index=offset,
        end_index=offset + position_dims,
        dims=position_dims,
        curriculum_active=True,
        description="Agent velocity vector"
    ))
    offset += position_dims

    # Meters (always active)
    meter_count = len(environment.meters.meters)
    fields.append(ObservationField(
        name="obs_meters",
        start_index=offset,
        end_index=offset + meter_count,
        dims=meter_count,
        curriculum_active=True,
        description=f"{meter_count} meter values (energy, health, etc.)"
    ))
    offset += meter_count

    # Affordances (always active, fixed vocabulary)
    affordance_count = len(environment.affordances.affordances)
    fields.append(ObservationField(
        name="obs_affordances",
        start_index=offset,
        end_index=offset + affordance_count,
        dims=affordance_count,
        curriculum_active=True,
        description=f"{affordance_count} affordance distances"
    ))
    offset += affordance_count

    # Temporal (Support/Active pattern)
    if stratum.temporal.support:
        is_active = curriculum.active_temporal
        temporal_dims = 4  # (time_of_day_sin, time_of_day_cos, day_progress, is_night)

        fields.append(ObservationField(
            name="obs_temporal",
            start_index=offset,
            end_index=offset + temporal_dims,
            dims=temporal_dims,
            curriculum_active=is_active,
            description="Temporal features (time of day, day progress)" if is_active else "Masked (inactive this level)"
        ))
        offset += temporal_dims

    total_dims = offset

    return ObservationSpec(
        fields=fields,
        total_dims=total_dims,
        curriculum_level=curriculum.version  # e.g., "1.0.0"
    )

def _compute_grid_encoding_dims(substrate_config) -> int:
    """Compute grid encoding dimensions from substrate config."""
    if substrate_config.substrate_type != "grid":
        return 0
    size = substrate_config.grid.size
    dims = substrate_config.grid.dimensions
    return size ** dims  # e.g., 8^2 = 64 for 8Ã—8 Grid2D
```

**Step 2: Call observation spec builder in compile_universe**

Add after Stage 2:

```python
def compile_universe(experiment_dir: Path) -> CompiledUniverse:
    """[docstring]"""

    # Stage 1: Load hierarchical structure
    (experiment, stratum, environment, actions, agent, levels_dict) = _load_experiment_structure(experiment_dir)

    # Stage 2: Cross-curriculum vocabulary validation
    _validate_vocabulary_consistency(environment, levels_dict)

    # Stage 3-4: [Symbol table, resolve references - keep existing logic]

    # Stage 5: Observation spec (for first level only, as proof of concept)
    first_level_name = sorted(levels_dict.keys())[0]
    curriculum, bars, affordances, training = levels_dict[first_level_name]

    obs_spec = _build_observation_spec(stratum, environment, curriculum, agent)

    print(f"\nâœ“ Observation spec for {first_level_name}:")
    print(f"  Total dims: {obs_spec.total_dims}")
    print(f"  Active dims: {sum(f.dims for f in obs_spec.fields if f.curriculum_active)}")
    print(f"  Masked dims: {sum(f.dims for f in obs_spec.fields if not f.curriculum_active)}")
    for field in obs_spec.fields:
        status = "ACTIVE" if field.curriculum_active else "MASKED"
        print(f"    [{field.start_index:3d}:{field.end_index:3d}] {field.name:20s} ({field.dims:3d} dims) {status}")

    # [Continue with rest of compilation...]
```

**Step 3: Test observation spec calculation**
```bash
export PYTHONPATH=$(pwd)/src:$PYTHONPATH
python3 << 'PYTEST'
from pathlib import Path
from townlet.universe.compiler import compile_universe

# This will fail because compile_universe isn't complete yet, but will print obs spec
try:
    compiled = compile_universe(Path("configs/default_curriculum"))
except Exception as e:
    # Expected to fail, but we should see obs spec printout
    print(f"\nExpected failure: {e}")
    print("Check above for observation spec printout")
PYTEST
```

**Expected Output**: Should print observation spec breakdown showing:
- L1: obs_grid_encoding ACTIVE (64 dims), obs_local_window MASKED (25 dims)
- Total dims around 121 (64 grid + 25 window + 2 pos + 2 vel + 8 meters + 15 affordances + 4 temporal + 1 padding)

**Step 4: Commit Stage 5**
```bash
git add src/townlet/universe/compiler.py
git commit -m "feat(compiler): implement Stage 5 - observation spec with Support/Active

- Add _build_observation_spec() with Support/Active pattern
- Stratum declares which fields CAN exist (vision.support, temporal.support)
- Curriculum declares which fields ARE active (active_vision, active_temporal)
- Masked fields included in obs_dim but zeroed out (enables transfer learning)"
```

### Task 4.5: Wire up remaining compilation stages

**Files:**
- Edit: `src/townlet/universe/compiler.py`

**Note**: This task depends heavily on existing compiler logic. The goal is to adapt existing Stages 3-7 to work with new DTOs.

**Step 1: Audit existing compiler stages**
```bash
python3 << 'PYTEST'
import inspect
from townlet.universe.compiler import compile_universe

source = inspect.getsource(compile_universe)

# Find all stage comments
import re
stages = re.findall(r'# Stage \d+:.*', source)
for stage in stages:
    print(stage)
PYTEST
```

**Expected Output**: Shows existing stage structure (if any)

**Step 2: Adapt existing logic or stub out temporarily**

The exact changes depend on existing compiler implementation. Key adaptations needed:

1. **Stage 3 (Symbol table)**: Build symbol table from `environment.yaml` vocabulary
2. **Stage 4 (Resolve references)**: Resolve affordance dependencies using `environment.affordances`
3. **Stage 6 (Optimization)**: Cache compiled universe with `drive_hash`
4. **Stage 7 (Emit)**: Return `CompiledUniverse` with all configs

**Temporary stub** (if existing logic is complex):

```python
def compile_universe(experiment_dir: Path) -> CompiledUniverse:
    """[docstring]"""

    # Stages 1-2-5 implemented above

    # Stage 3-4: Symbol table and resolution (TODO: adapt existing logic)
    # For now, stub out

    # Stage 6-7: Optimization and emit
    # Return minimal CompiledUniverse for testing

    from townlet.universe.compiled import CompiledUniverse

    return CompiledUniverse(
        experiment=experiment,
        stratum=stratum,
        environment=environment,
        actions=actions,
        agent=agent,
        curriculum_levels=levels_dict,
        observation_spec=obs_spec,
        # ... other fields TBD
    )
```

**Step 3: Test minimal compilation**
```bash
export PYTHONPATH=$(pwd)/src:$PYTHONPATH
python3 << 'PYTEST'
from pathlib import Path
from townlet.universe.compiler import compile_universe

compiled = compile_universe(Path("configs/default_curriculum"))

print(f"âœ“ Compiled experiment: {compiled.experiment.metadata.name}")
print(f"âœ“ Curriculum levels: {list(compiled.curriculum_levels.keys())}")
print(f"âœ“ Observation spec: {compiled.observation_spec.total_dims} dims")

print("\nSUCCESS: Minimal compilation working")
PYTEST
```

**Step 4: Commit minimal compiler**
```bash
git add src/townlet/universe/compiler.py
git commit -m "feat(compiler): minimal v2.1 compilation working

- Stages 1-2-5 implemented (load, validate, obs spec)
- Stages 3-4-6-7 stubbed for now (will adapt existing logic)
- Returns CompiledUniverse with all v2.1 configs"
```

**Phase 4 Complete!** Compiler now loads v2.1 structure and validates vocabulary.

---

## Phase 5: Test Updates (2-3 hours)

**Objective**: Fix broken tests incrementally, using failures as guide.

**Success Criteria**:
- All tests pass with v2.1 config structure
- No tests skipped or disabled

### Task 5.1: Run test suite and capture failures

**Step 1: Run full test suite**
```bash
UV_CACHE_DIR=.uv-cache PYTHONPATH=$(pwd)/src uv run pytest tests/test_townlet/ -v --tb=short > test_failures.txt 2>&1
echo "Exit code: $?" >> test_failures.txt
```

**Step 2: Analyze failure patterns**
```bash
grep -E "FAILED|ERROR" test_failures.txt | head -20
```

**Expected Output**: List of failing tests, likely patterns:
- `FileNotFoundError: substrate.yaml` (tests expecting flat structure)
- `AttributeError: 'NoneType' object has no attribute 'bars'` (missing config loading)
- `AssertionError: obs_dim mismatch` (hardcoded dimensions)

**Step 3: Categorize failures**
```bash
python3 << 'PYTEST'
import re

with open("test_failures.txt") as f:
    content = f.read()

# Extract all FAILED lines
failures = re.findall(r'FAILED (.*?) - (.*)', content)

# Categorize by error type
categories = {}
for test_path, error in failures:
    error_type = error.split(':')[0] if ':' in error else error
    categories.setdefault(error_type, []).append(test_path)

print("Failure categories:")
for error_type, tests in sorted(categories.items(), key=lambda x: -len(x[1])):
    print(f"\n{error_type} ({len(tests)} tests):")
    for test in tests[:5]:  # Show first 5
        print(f"  - {test}")
    if len(tests) > 5:
        print(f"  ... and {len(tests)-5} more")
PYTEST
```

**Step 4: Create test fix checklist**
```bash
cat >> docs/bugs/BUNDLE-01-curriculum-observation-architecture/test-fix-checklist.md << 'EOF'
# Test Fix Checklist

**Generated**: 2025-11-15
**Phase**: 5 - Test Updates

## Failure Categories

[Paste output from categorization above]

## Fix Strategy

For each category:
1. Fix one representative test
2. Verify pattern works
3. Apply pattern to remaining tests in category
4. Commit batch of fixes

## Tracking

- [ ] Category 1: FileNotFoundError (flat config paths)
- [ ] Category 2: AttributeError (missing config objects)
- [ ] Category 3: AssertionError (hardcoded obs_dim)
- [ ] Category 4: Other failures
- [ ] All tests passing

EOF

cat docs/bugs/BUNDLE-01-curriculum-observation-architecture/test-fix-checklist.md
```

**Step 5: Commit test failure analysis**
```bash
git add test_failures.txt docs/bugs/BUNDLE-01-curriculum-observation-architecture/test-fix-checklist.md
git commit -m "test: capture test failures for v2.1 migration

- 144 tests run, XX failed
- Failures categorized by error type
- Fix strategy documented in test-fix-checklist.md"
```

### Task 5.2: Fix Category 1 - Config path failures

**Context**: Tests expecting flat `config_dir/*.yaml` now need hierarchical `experiment_dir/levels/L*/*.yaml`

**Step 1: Find example test with FileNotFoundError**
```bash
grep -A 5 "FileNotFoundError.*substrate.yaml" test_failures.txt | head -20
```

**Step 2: Fix representative test**

Example fix pattern:

```python
# OLD (flat structure)
def test_something():
    config_dir = Path("configs/L1_full_observability")
    substrate_config = SubstrateConfig.from_yaml(config_dir / "substrate.yaml")

# NEW (hierarchical structure)
def test_something():
    experiment_dir = Path("configs/default_curriculum")
    level_dir = experiment_dir / "levels" / "L1_full_observability"

    # Load stratum instead of substrate
    stratum_config = StratumConfig.from_yaml(experiment_dir / "stratum.yaml")
    substrate_config = stratum_config.substrate  # Extract substrate from stratum
```

**Step 3: Test the fix**
```bash
UV_CACHE_DIR=.uv-cache PYTHONPATH=$(pwd)/src uv run pytest tests/test_townlet/path/to/test.py::test_something -v
```

**Expected Output**: Test passes

**Step 4: Apply pattern to all similar tests**
```bash
# Find all tests loading substrate.yaml directly
grep -r "substrate.yaml" tests/test_townlet/ --include="*.py"

# Fix each one following the pattern above
```

**Step 5: Commit batch fix**
```bash
git add tests/test_townlet/
git commit -m "test: fix config path failures for v2.1 structure

- Update tests loading substrate.yaml â†’ stratum.yaml
- Update tests loading bars.yaml â†’ use hierarchical levels/ path
- Pattern: experiment_dir/levels/L*/config.yaml instead of config_dir/config.yaml"
```

### Task 5.3: Fix Category 2 - Missing config object failures

**Context**: Tests expecting single config object now need to load from compiled universe

**Step 1: Find example test with AttributeError**
```bash
grep -A 5 "AttributeError.*bars" test_failures.txt | head -20
```

**Step 2: Fix representative test**

Example fix pattern:

```python
# OLD (direct config loading)
def test_something():
    bars_config = BarsConfig.from_yaml(config_dir / "bars.yaml")
    assert bars_config.bars[0].name == "energy"

# NEW (load from compiled universe)
def test_something():
    from townlet.universe.compiler import compile_universe

    compiled = compile_universe(Path("configs/default_curriculum"))
    curriculum, bars, affordances, training = compiled.curriculum_levels["L1_full_observability"]

    assert bars.bars[0].name == "energy"
```

**Step 3: Test the fix and apply pattern**

(Same as Task 5.2 steps 3-5)

### Task 5.4: Fix Category 3 - Hardcoded observation dimension failures

**Context**: obs_dim calculations now need to account for Support/Active pattern

**Step 1: Find example test with obs_dim mismatch**
```bash
grep -A 5 "AssertionError.*obs_dim" test_failures.txt | head -20
```

**Step 2: Fix representative test**

Example fix pattern:

```python
# OLD (hardcoded calculation)
def test_obs_dim():
    expected_dim = 64 + 2 + 2 + 8 + 15 + 4  # grid + pos + vel + meters + affordances + temporal
    assert env.obs_dim == expected_dim

# NEW (use observation spec)
def test_obs_dim():
    obs_spec = env.universe.observation_spec
    expected_dim = obs_spec.total_dims  # Use compiled spec

    # Or if you need to verify specific fields:
    grid_field = next(f for f in obs_spec.fields if f.name == "obs_grid_encoding")
    assert grid_field.dims == 64
    assert grid_field.curriculum_active == True  # L1 uses global vision
```

**Step 3: Test the fix and apply pattern**

(Same as Task 5.2 steps 3-5)

### Task 5.5: Verify all tests passing

**Step 1: Run full test suite**
```bash
UV_CACHE_DIR=.uv-cache PYTHONPATH=$(pwd)/src uv run pytest tests/test_townlet/ -v --tb=short
```

**Expected Output**: All 144 tests pass

**Step 2: Update test fix checklist**
```bash
# Mark all categories complete in test-fix-checklist.md
```

**Step 3: Commit Phase 5 completion**
```bash
git add tests/test_townlet/ docs/bugs/BUNDLE-01-curriculum-observation-architecture/test-fix-checklist.md
git commit -m "test: all 144 tests passing with v2.1 config structure

Phase 5 complete:
- Fixed config path failures (flat â†’ hierarchical)
- Fixed missing config object failures (direct load â†’ compiled universe)
- Fixed obs_dim calculation failures (hardcoded â†’ observation spec)
- All tests now use v2.1 config structure"
```

**Phase 5 Complete!** All tests passing with v2.1 structure.

---

## Phase 6: Remaining Curriculum Levels (1-2 hours)

**Objective**: Create v2.1 configs for L0_0, L0_5, L2, L3 (L1 already complete).

**Success Criteria**:
- All 5 curriculum levels have v2.1 configs
- Each level compiles successfully
- obs_dim correct for each level

### Task 6.1: Create L0_0_minimal configs

**Files:**
- Create: `configs/default_curriculum/levels/L0_0_minimal/curriculum.yaml`
- Create: `configs/default_curriculum/levels/L0_0_minimal/bars.yaml`
- Create: `configs/default_curriculum/levels/L0_0_minimal/affordances.yaml`
- Create: `configs/default_curriculum/levels/L0_0_minimal/training.yaml`

**Step 1: Create directory**
```bash
mkdir -p configs/default_curriculum/levels/L0_0_minimal
```

**Step 2: Create curriculum.yaml**

```bash
cat > configs/default_curriculum/levels/L0_0_minimal/curriculum.yaml << 'EOF'
version: "1.0.0"

# L0_0: Minimal temporal credit assignment (3Ã—3 grid, 1 affordance)
active_vision: global  # Full grid observable
active_temporal: false  # No time-based dynamics
vision_range: 1.0  # Full grid (but only 3Ã—3)
day_length: null  # No temporal mechanics
EOF
```

**Step 3: Create bars.yaml (minimal: only energy)**

From reference template, extract only energy bar with minimal config:

```bash
cat > configs/default_curriculum/levels/L0_0_minimal/bars.yaml << 'EOF'
bars:
  - name: energy
    depletion_rate: 0.01
    depletion_type: constant
    depletion_variance: 0.0
    critical_threshold: 0.2
    ranges:
      healthy: [0.5, 1.0]
      moderate: [0.2, 0.5]
      critical: [0.0, 0.2]

    cascades:
      - target: energy  # Self-referential (no cross-bar cascades in L0_0)
        strength: 0.0
        threshold: 0.0
        effect_type: proportional
EOF
```

**Step 4: Create affordances.yaml (minimal: only RECHARGE)**

```bash
cat > configs/default_curriculum/levels/L0_0_minimal/affordances.yaml << 'EOF'
affordances:
  - name: RECHARGE
    max_instances: 3
    effects:
      - bar: energy
        delta: 0.5
        delta_type: absolute
    costs: []
    preconditions: []
    interaction_radius: 1.0
    respawn: true
    respawn_turns: 20
EOF
```

**Step 5: Create training.yaml (same as L1)**

```bash
cat > configs/default_curriculum/levels/L0_0_minimal/training.yaml << 'EOF'
episodes: 10000
max_steps_per_episode: 1000
batch_size: 32
target_update_frequency: 500
use_double_dqn: false
gradient_clip_max_norm: 10.0
learning_rate: 0.0001
gamma: 0.99
replay_buffer_capacity: 100000
num_agents: 256
curriculum:
  strategy: static
static_curriculum: {}
adversarial_curriculum: {}
exploration:
  strategy: adaptive_rnd
  epsilon_greedy: {}
  rnd: {}
  adaptive_rnd:
    initial_weight: 0.1
    min_weight: 0.001
    annealing_threshold: 100.0
checkpoint:
  save_frequency: 1000
  keep_last_n: 5
EOF
```

**Step 6: Test L0_0 compiles**
```bash
export PYTHONPATH=$(pwd)/src:$PYTHONPATH
python3 << 'PYTEST'
from pathlib import Path
from townlet.universe.compiler import compile_universe

compiled = compile_universe(Path("configs/default_curriculum"))
curriculum, bars, affordances, training = compiled.curriculum_levels["L0_0_minimal"]

print(f"âœ“ L0_0 compiled successfully")
print(f"  Bars: {[b.name for b in bars.bars]}")
print(f"  Affordances: {[a.name for a in affordances.affordances]}")
print(f"  Vision: {curriculum.active_vision}")

assert len(bars.bars) == 1
assert bars.bars[0].name == "energy"
assert len(affordances.affordances) == 1
print("\nSUCCESS: L0_0 working")
PYTEST
```

**Step 7: Commit L0_0**
```bash
git add configs/default_curriculum/levels/L0_0_minimal/
git commit -m "feat(config): add L0_0_minimal v2.1 config

- Temporal credit assignment level (3Ã—3 grid, 1 affordance)
- Only energy meter + RECHARGE affordance
- Full observability, no temporal mechanics"
```

### Task 6.2: Create L0_5_dual_resource configs

**Pattern**: Same as Task 6.1, but with multiple meters

**Key differences from L0_0**:
- 2 bars: energy + health
- 4 affordances: RECHARGE, HEAL, REST, WORK
- 7Ã—7 grid (stratum.yaml already has this)
- Cascades: energy â†’ health depletion

**Step 1: Create directory**
```bash
mkdir -p configs/default_curriculum/levels/L0_5_dual_resource
```

**Step 2-6: Extract from reference template**

Follow same pattern as Task 6.1, but include:
- `bars.yaml`: energy + health with cascade
- `affordances.yaml`: RECHARGE, HEAL, REST, WORK
- `curriculum.yaml`: active_vision=global, active_temporal=false

**Step 7: Test and commit**

(Same as Task 6.1 steps 6-7)

### Task 6.3: Create L2_partial_observability configs

**Pattern**: Same as L1, but with partial observability

**Key differences from L1**:
- `curriculum.yaml: active_vision: partial` (instead of global)
- `curriculum.yaml: vision_range: 0.625` (5Ã—5 window on 8Ã—8 grid)
- Same bars/affordances as L1 (full vocabulary)

**Steps**: Same as Task 6.1, extract from reference template

### Task 6.4: Create L3_temporal_mechanics configs

**Pattern**: Same as L1, but with temporal mechanics active

**Key differences from L1**:
- `curriculum.yaml: active_temporal: true`
- `curriculum.yaml: day_length: 24`
- Same bars/affordances as L1

**Steps**: Same as Task 6.1, extract from reference template

### Task 6.5: Verify all levels compile with correct obs_dim

**Step 1: Test all levels compile**
```bash
export PYTHONPATH=$(pwd)/src:$PYTHONPATH
python3 << 'PYTEST'
from pathlib import Path
from townlet.universe.compiler import compile_universe

compiled = compile_universe(Path("configs/default_curriculum"))

for level_name, (curriculum, bars, affordances, training) in sorted(compiled.curriculum_levels.items()):
    # Recompile obs_spec for this level (if needed per-level)
    # For now, just verify it loaded
    print(f"âœ“ {level_name:30s} - {len(bars.bars)} bars, {len(affordances.affordances)} affordances, vision={curriculum.active_vision}")

print("\nSUCCESS: All 5 levels compile")
PYTEST
```

**Expected Output**:
```
âœ“ L0_0_minimal                 - 1 bars, 1 affordances, vision=global
âœ“ L0_5_dual_resource           - 2 bars, 4 affordances, vision=global
âœ“ L1_full_observability        - 8 bars, 14 affordances, vision=global
âœ“ L2_partial_observability     - 8 bars, 14 affordances, vision=partial
âœ“ L3_temporal_mechanics        - 8 bars, 14 affordances, vision=global
```

**Step 2: Verify obs_dim for each level**

```bash
export PYTHONPATH=$(pwd)/src:$PYTHONPATH
python3 << 'PYTEST'
from pathlib import Path
from townlet.universe.compiler import compile_universe, _build_observation_spec
from townlet.config.stratum_config import StratumConfig
from townlet.config.environment_config import EnvironmentConfig
from townlet.config.agent_config import AgentConfig

experiment_dir = Path("configs/default_curriculum")
compiled = compile_universe(experiment_dir)

# Load shared configs
stratum = StratumConfig.from_yaml(experiment_dir / "stratum.yaml")
environment = EnvironmentConfig.from_yaml(experiment_dir / "environment.yaml")
agent = AgentConfig.from_yaml(experiment_dir / "agent.yaml")

# Compute obs_dim for each level
for level_name, (curriculum, bars, affordances, training) in sorted(compiled.curriculum_levels.items()):
    obs_spec = _build_observation_spec(stratum, environment, curriculum, agent)
    active_dims = sum(f.dims for f in obs_spec.fields if f.curriculum_active)
    masked_dims = sum(f.dims for f in obs_spec.fields if not f.curriculum_active)

    print(f"{level_name:30s} obs_dim={obs_spec.total_dims:3d} (active={active_dims:3d}, masked={masked_dims:3d})")

print("\nExpected obs_dim:")
print("  L0_0, L0_5, L1, L3: ~96-121 (depending on grid size)")
print("  L2: Same total_dims, different active/masked split")
PYTEST
```

**Expected Output**: All levels have consistent obs_dim (enables transfer learning)

**Step 3: Commit Phase 6 completion**
```bash
git add configs/default_curriculum/levels/
git commit -m "feat(config): add all 5 curriculum levels with v2.1 structure

Phase 6 complete:
- L0_0_minimal: Temporal credit assignment (1 bar, 1 affordance)
- L0_5_dual_resource: Multiple resources (2 bars, 4 affordances)
- L1_full_observability: Full obs baseline (8 bars, 14 affordances)
- L2_partial_observability: POMDP with 5Ã—5 window
- L3_temporal_mechanics: Time-based dynamics (24-tick day/night)

All levels compile successfully with consistent vocabulary"
```

**Phase 6 Complete!** All curriculum levels migrated to v2.1.

---

## Phase 7: Cleanup & Validation (30 minutes)

**Objective**: Final validation and merge to main.

**Success Criteria**:
- All tests pass
- No old config references remain
- Clean git history
- Merged to main

### Task 7.1: Final test validation

**Step 1: Run full test suite one more time**
```bash
UV_CACHE_DIR=.uv-cache PYTHONPATH=$(pwd)/src uv run pytest tests/test_townlet/ -v
```

**Expected Output**: All 144 tests pass

**Step 2: Run training smoke test for each level**
```bash
for config in L0_0_minimal L0_5_dual_resource L1_full_observability L2_partial_observability L3_temporal_mechanics; do
    echo "Testing $config..."
    timeout 30 UV_CACHE_DIR=.uv-cache PYTHONPATH=$(pwd)/src uv run python scripts/run_demo.py --config configs/default_curriculum/levels/$config --episodes 10 || echo "FAILED: $config"
done
```

**Expected Output**: Each level runs for 10 episodes without crashes

**Step 3: Verify no compilation errors**
```bash
UV_CACHE_DIR=.uv-cache uv run python -m py_compile src/townlet/universe/compiler.py
UV_CACHE_DIR=.uv-cache uv run python -m py_compile src/townlet/config/*.py
```

**Expected Output**: No syntax errors

### Task 7.2: Remove archived configs

**Step 1: Verify archived configs not used anywhere**
```bash
grep -r "configs_archive" src/ tests/ --include="*.py" || echo "No references found (good!)"
grep -r "configs/L.*_" src/ tests/ --include="*.py" | grep -v "default_curriculum" || echo "No old flat paths found (good!)"
```

**Expected Output**: No references to old config paths

**Step 2: Delete archived configs**
```bash
rm -rf configs_archive/
git add -A
git commit -m "chore: remove archived v1 configs

All configs migrated to v2.1 hierarchical structure.
Old flat configs no longer needed."
```

### Task 7.3: Update documentation references

**Step 1: Update CLAUDE.md config section**
```bash
# Edit CLAUDE.md section on config structure to reference v2.1 hierarchy
```

**Step 2: Update ENH-28 status**
```bash
# Edit docs/bugs/BUNDLE-01-curriculum-observation-architecture/ENH-28-*.md
# Status: design-v2.1-complete â†’ implemented
```

**Step 3: Commit doc updates**
```bash
git add CLAUDE.md docs/bugs/BUNDLE-01-curriculum-observation-architecture/
git commit -m "docs: update for v2.1 config implementation

- CLAUDE.md: reference hierarchical structure
- ENH-28: status â†’ implemented"
```

### Task 7.4: Final checklist review

**Step 1: Check implementation checklist**
```bash
cat docs/bugs/BUNDLE-01-curriculum-observation-architecture/implementation-checklist.md
```

**Expected**: All items checked

**Step 2: Verify git log clean**
```bash
git log --oneline feature/config-v2.1 --not main | head -20
```

**Expected Output**: Clean sequence of commits (Setup â†’ Model config â†’ DTOs â†’ Compiler â†’ Tests â†’ Remaining levels â†’ Cleanup)

**Step 3: Mark Phase 7 complete**
```bash
echo "## Phase 7: COMPLETE

All tasks completed:
- âœ… All tests pass (144/144)
- âœ… All 5 curriculum levels compile
- âœ… Archived configs removed
- âœ… Documentation updated
- âœ… Ready for merge

$(date)" >> docs/bugs/BUNDLE-01-curriculum-observation-architecture/implementation-checklist.md

git add docs/bugs/BUNDLE-01-curriculum-observation-architecture/implementation-checklist.md
git commit -m "docs: mark Phase 7 complete, ready for merge"
```

### Task 7.5: Merge to main

**Step 1: Final pre-merge check**
```bash
git checkout main
git pull origin main  # Ensure up to date
git checkout feature/config-v2.1

# Verify no conflicts
git merge main --no-commit --no-ff
git merge --abort  # Just checking, don't actually merge yet
```

**Step 2: Merge feature branch**
```bash
git checkout main
git merge feature/config-v2.1 --no-ff -m "feat: implement config v2.1 hierarchical structure (ENH-28)

BREAKING CHANGE: Config structure changed from flat to hierarchical

Old structure:
  configs/L1_full_observability/*.yaml (flat files)

New structure:
  configs/default_curriculum/
    â”œâ”€â”€ experiment.yaml
    â”œâ”€â”€ stratum.yaml
    â”œâ”€â”€ environment.yaml
    â”œâ”€â”€ actions.yaml
    â”œâ”€â”€ agent.yaml
    â””â”€â”€ levels/L1_full_observability/*.yaml

Benefits:
- Cross-curriculum vocabulary consistency enforced
- Observation spec with Support/Active pattern (enables transfer learning)
- WHAT vs HOW split (vocabulary vs parameters)
- Normalized vision_range (0.0-1.0)
- No-defaults principle enforced

Implementation:
- Phase 1: Setup & safety net
- Phase 2: Model config (L1 reference)
- Phase 3: DTO creation (6 Pydantic DTOs)
- Phase 4: Compiler updates (7-stage pipeline)
- Phase 5: Test updates (144 tests passing)
- Phase 6: Remaining levels (L0_0, L0_5, L2, L3)
- Phase 7: Cleanup & validation

See docs/bugs/BUNDLE-01-curriculum-observation-architecture/ for complete design and implementation docs.

Closes ENH-28"
```

**Step 3: Push to main**
```bash
git push origin main
```

**Step 4: Delete feature branch**
```bash
git branch -d feature/config-v2.1
```

**Step 5: Celebrate!**
```bash
echo "ðŸŽ‰ Config v2.1 implementation complete!"
echo ""
echo "Summary:"
echo "- 5 curriculum levels migrated to v2.1"
echo "- 144 tests passing"
echo "- Hierarchical structure enforcing cross-curriculum consistency"
echo "- Support/Active pattern enabling transfer learning"
echo "- Clean git history with documented implementation phases"
echo ""
echo "Next steps:"
echo "- Run full training on all levels to verify behavior"
echo "- Monitor for any runtime issues with new structure"
echo "- Consider power user optimization modes (future enhancement)"
```

**Phase 7 Complete!** Config v2.1 implemented and merged to main.

---

## Summary

**Total Time**: ~8-10 hours (depending on test complexity)

**Phases**:
1. âœ… Setup & Safety Net (30 min) - 4 tasks
2. âœ… Create Model Config (1 hour) - 13 tasks
3. âœ… DTO Creation (2-3 hours) - 8 tasks
4. âœ… Compiler Updates (2-3 hours) - 5 tasks
5. âœ… Test Updates (2-3 hours) - 5 tasks
6. âœ… Remaining Levels (1-2 hours) - 5 tasks
7. âœ… Cleanup & Validation (30 min) - 5 tasks

**Total Tasks**: 45 bite-sized tasks (2-5 minutes each)

**Deliverables**:
- Hierarchical config structure (experiment + stratum + environment + agent + curriculum)
- 6 new Pydantic DTOs with strict validation
- Updated compiler with cross-curriculum vocabulary validation
- Observation spec with Support/Active pattern
- 5 curriculum levels migrated (L0_0, L0_5, L1, L2, L3)
- 144 tests passing
- Complete documentation and clean git history

**Key Patterns**:
- Support vs Active (experiment declares fields that CAN exist, curriculum declares which ARE active)
- WHAT vs HOW (vocabulary breaks checkpoints, parameters don't)
- No-defaults principle (all settings mandatory)
- Test-driven validation (let failures guide fixes)
- Clean-break migration (no backwards compatibility)

**Risk Mitigation**:
- Feature branch = safe sandbox
- Baseline test results captured
- Implementation checklist tracking
- Strict DTO validation
- obs_dim validation after each level
- grep for old code before merge

**Success Metrics**:
- All 144 tests pass
- All 5 levels compile successfully
- obs_dim consistent across curriculum (enables transfer learning)
- No old config references remain
- Clean git history with documented phases
- Merged to main without conflicts

---

**Next Steps After Implementation**:

1. **Training Validation**: Run full training on all levels to verify behavior unchanged
2. **Performance Testing**: Compare training speed v1 vs v2.1
3. **Power User Optimization**: Consider future enhancement for observation_policy modes (minimal, curriculum_superset, explicit)
4. **Multi-Experiment Support**: Consider future enhancement for experiments/ directory with multiple experiments
5. **Documentation**: Update user-facing docs with new config structure examples
