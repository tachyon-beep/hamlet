# Config v2.1 Phases 4-7 Implementation Plan

> **For Claude:** REQUIRED SUB-SKILL: Use superpowers:executing-plans to implement this plan task-by-task.

**Goal:** Complete config v2.1 migration by updating compiler, fixing tests, migrating remaining curriculum levels, and merging to main.

**Architecture:** Update compiler to load hierarchical v2.1 structure with 7-stage pipeline (load → validate → symbol table → resolve → observation spec → optimize → emit). Fix tests incrementally using test-driven validation. Replicate L1 pattern for L0_0, L0_5, L2, L3.

**Tech Stack:** Python 3.10+, Pydantic DTOs, pytest, YAML configs, git feature branch workflow

**Prerequisites:** Phases 1-3 complete (branch created, model config extracted, DTOs created)

---

## Phase 4: Compiler Updates (2-3 hours)

### Task 4.1: Read current compiler structure

**Files:**
- Read: `src/townlet/universe/compiler.py`

**Step 1: Examine current compiler function signature**

```bash
export PYTHONPATH=$(pwd)/src:$PYTHONPATH
python3 << 'PYTEST'
from pathlib import Path
import inspect
from townlet.universe.compiler import compile_universe

# Print current signature
sig = inspect.signature(compile_universe)
print(f"Current signature: compile_universe{sig}")

# Print function source (first 30 lines)
source_lines = inspect.getsource(compile_universe).split('\n')[:30]
print("\nFirst 30 lines:")
for i, line in enumerate(source_lines, 1):
    print(f"{i:3}: {line}")
PYTEST
```

Expected output: Shows current `compile_universe(config_dir: Path)` signature and existing logic

**Step 2: Document current return type**

```bash
python3 << 'PYTEST'
from townlet.universe.compiler import compile_universe
import inspect

# Get return annotation
sig = inspect.signature(compile_universe)
print(f"Return type: {sig.return_annotation}")

# Try to find CompiledUniverse class
try:
    from townlet.universe.compiled import CompiledUniverse
    print(f"CompiledUniverse exists: {CompiledUniverse}")
except ImportError as e:
    print(f"CompiledUniverse not found: {e}")
PYTEST
```

Expected output: Shows return type (likely a dict or custom class)

**Step 3: Note findings in task tracking**

Create notes file for reference:

```bash
cat > /tmp/compiler_current_state.txt << 'EOF'
Current Compiler State (before v2.1 migration)
=============================================

Signature: compile_universe(config_dir: Path) -> [return_type]

Key observations:
- [Note what you found about current structure]
- [Note any existing stage comments]
- [Note return type and structure]

Files it currently loads:
- [List flat YAML files it loads]

Changes needed for v2.1:
- Change param from config_dir to experiment_dir
- Load hierarchical structure (5 shared + N curriculum levels)
- Add cross-curriculum vocabulary validation
- Add Support/Active pattern to observation spec
EOF

cat /tmp/compiler_current_state.txt
```

No commit yet - just reconnaissance.

### Task 4.2: Update compiler function signature and docstring

**Files:**
- Modify: `src/townlet/universe/compiler.py` (function signature and docstring)

**Step 1: Update function signature**

Find the `def compile_universe(` line and change:

```python
# OLD
def compile_universe(config_dir: Path) -> CompiledUniverse:
    """Compile flat config structure..."""

# NEW
def compile_universe(experiment_dir: Path) -> CompiledUniverse:
    """
    Compile hierarchical config v2.1 structure into a CompiledUniverse.

    Expected directory structure:
        experiment_dir/
        ├── experiment.yaml       # Metadata
        ├── stratum.yaml          # World shape (substrate, grid, temporal)
        ├── environment.yaml      # Vocabulary (bars, affordances, VFS)
        ├── actions.yaml          # Action space configuration
        ├── agent.yaml            # Perception + Drive + Brain
        └── levels/
            ├── L1_full_observability/
            │   ├── curriculum.yaml   # Vision/temporal activation
            │   ├── bars.yaml         # Bar parameters + cascades
            │   ├── affordances.yaml  # Affordance parameters
            │   └── training.yaml     # Runtime orchestration
            └── [other levels]/

    Architecture:
    - Stage 1: Load hierarchical structure (5 shared + N curriculum levels)
    - Stage 2: Cross-curriculum vocabulary validation (WHAT vs HOW enforcement)
    - Stage 3: Build symbol table from environment.yaml
    - Stage 4: Resolve references and dependencies
    - Stage 5: Generate observation spec with Support/Active pattern
    - Stage 6: Optimize and cache
    - Stage 7: Emit CompiledUniverse

    Args:
        experiment_dir: Path to experiment root directory (contains experiment.yaml)

    Returns:
        CompiledUniverse with validated, cross-curriculum consistent configuration

    Raises:
        ValueError: If vocabulary inconsistent across curriculum levels
        FileNotFoundError: If required config files missing
    """
```

**Step 2: Verify no syntax errors**

```bash
python3 -m py_compile src/townlet/universe/compiler.py
```

Expected output: No errors (file compiles)

**Step 3: Commit signature change**

```bash
git add src/townlet/universe/compiler.py
git commit -m "refactor(compiler): update signature for v2.1 hierarchical structure

BREAKING CHANGE: compile_universe now expects experiment_dir not config_dir

- Old: compile_universe(config_dir) with flat *.yaml files
- New: compile_universe(experiment_dir) with layered structure
- Added comprehensive docstring documenting 7-stage architecture"
```

### Task 4.3: Implement Stage 1 helper - Load hierarchical structure

**Files:**
- Modify: `src/townlet/universe/compiler.py` (add `_load_experiment_structure` function before `compile_universe`)

**Step 1: Add helper function**

Add this function **before** `compile_universe`:

```python
def _load_experiment_structure(experiment_dir: Path) -> tuple:
    """
    Load all config files from hierarchical v2.1 structure.

    Returns:
        (experiment, stratum, environment, actions, agent, levels_dict)
        where levels_dict = {
            "L1_full_observability": (curriculum, bars, affordances, training),
            ...
        }
    """
    from townlet.config.experiment_config import ExperimentConfig
    from townlet.config.stratum_config import StratumConfig
    from townlet.config.environment_config import EnvironmentConfig
    from townlet.config.actions_config import ActionsConfig
    from townlet.config.agent_config import AgentConfig
    from townlet.config.curriculum_config import CurriculumConfig
    # These should already exist:
    from townlet.config.bars_config import BarsConfig
    from townlet.config.affordances_config import AffordancesConfig
    from townlet.config.training_config import TrainingConfig

    # Load shared configs (experiment-level)
    experiment = ExperimentConfig.from_yaml(experiment_dir / "experiment.yaml")
    stratum = StratumConfig.from_yaml(experiment_dir / "stratum.yaml")
    environment = EnvironmentConfig.from_yaml(experiment_dir / "environment.yaml")
    actions = ActionsConfig.from_yaml(experiment_dir / "actions.yaml")
    agent = AgentConfig.from_yaml(experiment_dir / "agent.yaml")

    # Load all curriculum levels
    levels_dir = experiment_dir / "levels"
    if not levels_dir.exists():
        raise FileNotFoundError(
            f"Missing levels/ directory in {experiment_dir}\n"
            f"Expected structure: {experiment_dir}/levels/L*/{{curriculum,bars,affordances,training}}.yaml"
        )

    levels_dict = {}
    for level_dir in sorted(levels_dir.iterdir()):
        if not level_dir.is_dir():
            continue

        level_name = level_dir.name

        # Load all 4 curriculum-level configs
        curriculum = CurriculumConfig.from_yaml(level_dir / "curriculum.yaml")
        bars = BarsConfig.from_yaml(level_dir / "bars.yaml")
        affordances = AffordancesConfig.from_yaml(level_dir / "affordances.yaml")
        training = TrainingConfig.from_yaml(level_dir / "training.yaml")

        levels_dict[level_name] = (curriculum, bars, affordances, training)

    if not levels_dict:
        raise ValueError(
            f"No curriculum levels found in {levels_dir}\n"
            f"Expected at least one level directory (e.g., levels/L1_full_observability/)"
        )

    return (experiment, stratum, environment, actions, agent, levels_dict)
```

**Step 2: Test the helper loads configs**

```bash
export PYTHONPATH=$(pwd)/src:$PYTHONPATH
python3 << 'PYTEST'
from pathlib import Path
from townlet.universe.compiler import _load_experiment_structure

experiment_dir = Path("configs/default_curriculum")

try:
    (experiment, stratum, environment, actions, agent, levels_dict) = _load_experiment_structure(experiment_dir)

    print(f"✓ Loaded experiment: {experiment.metadata.name}")
    print(f"✓ Stratum substrate: {stratum.substrate.substrate_type}")
    print(f"✓ Environment meters: {len(environment.meters.meters)}")
    print(f"✓ Environment affordances: {len(environment.affordances.affordances)}")
    print(f"✓ Curriculum levels: {list(levels_dict.keys())}")

    # Verify expected content
    assert experiment.metadata.name == "Default Curriculum"
    assert stratum.substrate.substrate_type == "grid"
    assert len(environment.meters.meters) == 8
    assert "L1_full_observability" in levels_dict

    print("\nSUCCESS: Stage 1 helper working correctly")
except Exception as e:
    print(f"FAILED: {e}")
    import traceback
    traceback.print_exc()
PYTEST
```

Expected output: All assertions pass, shows loaded config structure

**Step 3: Commit Stage 1 helper**

```bash
git add src/townlet/universe/compiler.py
git commit -m "feat(compiler): add Stage 1 helper to load v2.1 structure

- _load_experiment_structure() loads 5 shared + N curriculum configs
- Returns structured tuple (experiment, stratum, environment, actions, agent, levels_dict)
- Clear error messages for missing directories or files
- Tested loading configs/default_curriculum successfully"
```

### Task 4.4: Implement Stage 2 helper - Vocabulary validation

**Files:**
- Modify: `src/townlet/universe/compiler.py` (add `_validate_vocabulary_consistency` function)

**Step 1: Add validation helper**

Add this function **before** `compile_universe`:

```python
def _validate_vocabulary_consistency(environment: EnvironmentConfig, levels_dict: dict) -> None:
    """
    Validate that all curriculum levels use the same vocabulary as environment.yaml.

    Enforces the WHAT vs HOW split:
    - environment.yaml defines WHAT exists (vocabulary - breaks checkpoints)
    - levels/*/bars.yaml defines HOW bars behave (parameters - doesn't break)
    - levels/*/affordances.yaml defines HOW affordances behave (parameters - doesn't break)

    This ensures checkpoint portability across curriculum levels.

    Args:
        environment: Loaded EnvironmentConfig with canonical vocabulary
        levels_dict: Dict of {level_name: (curriculum, bars, affordances, training)}

    Raises:
        ValueError: If any level has different meter or affordance vocabulary
    """
    from townlet.config.environment_config import EnvironmentConfig

    # Get canonical vocabulary from environment.yaml
    env_meters = set(m.name for m in environment.meters.meters)
    env_affordances = set(a.name for a in environment.affordances.affordances)

    # Validate each curriculum level
    for level_name, (curriculum, bars, affordances, training) in levels_dict.items():
        # Check meter vocabulary matches
        level_meters = set(b.name for b in bars.bars)
        if level_meters != env_meters:
            missing = env_meters - level_meters
            extra = level_meters - env_meters

            msg_parts = [f"Meter vocabulary mismatch in {level_name}/bars.yaml:"]
            if missing:
                msg_parts.append(f"  Missing meters: {sorted(missing)}")
            if extra:
                msg_parts.append(f"  Extra meters: {sorted(extra)}")
            msg_parts.append(f"  Expected (from environment.yaml): {sorted(env_meters)}")
            msg_parts.append(f"  Actual (from bars.yaml): {sorted(level_meters)}")
            msg_parts.append("")
            msg_parts.append("All curriculum levels must have same meter vocabulary as environment.yaml")
            msg_parts.append("This ensures checkpoint portability across curriculum.")

            raise ValueError("\n".join(msg_parts))

        # Check affordance vocabulary matches
        level_affordances = set(a.name for a in affordances.affordances)
        if level_affordances != env_affordances:
            missing = env_affordances - level_affordances
            extra = level_affordances - env_affordances

            msg_parts = [f"Affordance vocabulary mismatch in {level_name}/affordances.yaml:"]
            if missing:
                msg_parts.append(f"  Missing affordances: {sorted(missing)}")
            if extra:
                msg_parts.append(f"  Extra affordances: {sorted(extra)}")
            msg_parts.append(f"  Expected (from environment.yaml): {sorted(env_affordances)}")
            msg_parts.append(f"  Actual (from affordances.yaml): {sorted(level_affordances)}")
            msg_parts.append("")
            msg_parts.append("All curriculum levels must have same affordance vocabulary as environment.yaml")
            msg_parts.append("This ensures checkpoint portability across curriculum.")

            raise ValueError("\n".join(msg_parts))

    # All levels validated - print confirmation
    print(f"✓ Vocabulary consistent across {len(levels_dict)} curriculum levels")
    print(f"  {len(env_meters)} meters: {sorted(env_meters)}")
    print(f"  {len(env_affordances)} affordances: {sorted(env_affordances)}")
```

**Step 2: Test validation passes on correct config**

```bash
export PYTHONPATH=$(pwd)/src:$PYTHONPATH
python3 << 'PYTEST'
from pathlib import Path
from townlet.universe.compiler import _load_experiment_structure, _validate_vocabulary_consistency

experiment_dir = Path("configs/default_curriculum")
(experiment, stratum, environment, actions, agent, levels_dict) = _load_experiment_structure(experiment_dir)

try:
    _validate_vocabulary_consistency(environment, levels_dict)
    print("\nSUCCESS: Vocabulary validation passed")
except ValueError as e:
    print(f"FAILED: {e}")
PYTEST
```

Expected output: Validation passes, shows consistent vocabulary

**Step 3: Test validation fails on mismatch (negative test)**

```bash
export PYTHONPATH=$(pwd)/src:$PYTHONPATH
python3 << 'PYTEST'
from pathlib import Path
from townlet.universe.compiler import _validate_vocabulary_consistency
from townlet.config.environment_config import EnvironmentConfig, MetersSection, MeterDef
from townlet.config.bars_config import BarsConfig, BarDef

# Create mock configs with vocabulary mismatch
environment = EnvironmentConfig(
    version="1.0.0",
    meters=MetersSection(meters=[MeterDef(name="energy", ...)]),  # Only energy
    affordances=...,  # Would need full structure
    vfs_variables=...
)

# Mock levels_dict with different meter
bars = BarsConfig(bars=[BarDef(name="health", ...)])  # Different meter!

# This should raise ValueError
try:
    # Note: This is a simplified negative test
    # Real test would need full valid configs
    print("Negative test structure validated")
    print("(Full negative test requires complete DTO instances)")
except Exception as e:
    print(f"Expected: Would catch vocabulary mismatch")
PYTEST
```

Expected output: Shows negative test structure (actual test needs full DTOs)

**Step 4: Commit Stage 2 validator**

```bash
git add src/townlet/universe/compiler.py
git commit -m "feat(compiler): add Stage 2 vocabulary validator

- _validate_vocabulary_consistency() enforces WHAT vs HOW split
- Validates meters and affordances match environment.yaml across all levels
- Clear error messages showing missing/extra items and expected vs actual
- Ensures checkpoint portability across curriculum levels"
```

### Task 4.5: Wire Stage 1-2 into compile_universe

**Files:**
- Modify: `src/townlet/universe/compiler.py` (update `compile_universe` function body)

**Step 1: Replace/update compile_universe body to use new stages**

Find the `compile_universe` function body and update the beginning:

```python
def compile_universe(experiment_dir: Path) -> CompiledUniverse:
    """[docstring from Task 4.2]"""

    print(f"Compiling experiment: {experiment_dir}")

    # Stage 1: Load hierarchical structure
    print("\n=== Stage 1: Loading hierarchical config structure ===")
    (experiment, stratum, environment, actions, agent, levels_dict) = _load_experiment_structure(experiment_dir)

    print(f"\nLoaded experiment: '{experiment.metadata.name}'")
    print(f"  Description: {experiment.metadata.description}")
    print(f"  Stratum: {stratum.substrate.substrate_type} ({stratum.substrate.grid.size}x{stratum.substrate.grid.size})")
    print(f"  Curriculum levels: {list(levels_dict.keys())}")

    # Stage 2: Cross-curriculum vocabulary validation
    print("\n=== Stage 2: Validating vocabulary consistency ===")
    _validate_vocabulary_consistency(environment, levels_dict)

    # Stage 3-7: TODO - implement remaining stages
    # For now, return minimal CompiledUniverse structure
    print("\n=== Stage 3-7: TODO (stubbed for now) ===")
    print("Will implement: symbol table, resolve, obs spec, optimize, emit")

    # Temporary return - will be replaced in later tasks
    # This allows us to test Stages 1-2 independently
    raise NotImplementedError(
        "Compiler Stages 3-7 not yet implemented\n"
        "Stages 1-2 working: hierarchical loading + vocabulary validation"
    )
```

**Step 2: Test Stages 1-2 work**

```bash
export PYTHONPATH=$(pwd)/src:$PYTHONPATH
python3 << 'PYTEST'
from pathlib import Path
from townlet.universe.compiler import compile_universe

try:
    compiled = compile_universe(Path("configs/default_curriculum"))
    print("UNEXPECTED: Should have raised NotImplementedError")
except NotImplementedError as e:
    print(f"✓ Expected NotImplementedError: {e}")
    print("\nSUCCESS: Stages 1-2 executed, Stage 3-7 stub reached")
except Exception as e:
    print(f"FAILED: Unexpected error: {e}")
    import traceback
    traceback.print_exc()
PYTEST
```

Expected output: NotImplementedError after Stages 1-2 complete successfully

**Step 3: Commit Stage 1-2 integration**

```bash
git add src/townlet/universe/compiler.py
git commit -m "feat(compiler): integrate Stages 1-2 into compile_universe

- compile_universe now uses hierarchical loading and validation
- Stages 1-2 working: load structure + validate vocabulary
- Stages 3-7 stubbed with NotImplementedError (will implement next)
- Tested on configs/default_curriculum successfully"
```

### Task 4.6: Implement Stage 5 - Observation spec builder (Support/Active pattern)

**Files:**
- Modify: `src/townlet/universe/compiler.py` (add `_build_observation_spec` function)

**Step 1: Add observation spec builder**

Add this function **before** `compile_universe`:

```python
def _build_observation_spec(
    stratum: StratumConfig,
    environment: EnvironmentConfig,
    curriculum: CurriculumConfig,
    agent: AgentConfig
) -> 'ObservationSpec':
    """
    Build observation spec using Support/Active pattern.

    Support (stratum): Which observation fields CAN exist (declared at experiment level)
    Active (curriculum): Which fields ARE active vs masked (varies per curriculum level)

    This enables:
    - Transfer learning: All levels have same obs_dim (masked fields = zeros)
    - Power user optimization: Future enhancement can exclude unsupported fields

    Args:
        stratum: Stratum config with vision/temporal support declarations
        environment: Environment config with meter/affordance vocabulary
        curriculum: Curriculum config with active vision/temporal settings
        agent: Agent config with perception settings

    Returns:
        ObservationSpec with all fields, marked as curriculum_active or masked
    """
    # Import here to avoid circular dependency issues
    from townlet.vfs.observation_builder import ObservationField, ObservationSpec

    fields = []
    offset = 0

    # ===== Vision Fields (Support/Active pattern) =====

    # Global vision (grid encoding)
    if stratum.vision.support in ["both", "global"]:
        is_active = (curriculum.active_vision == "global")

        # Compute grid encoding dimensions
        if stratum.substrate.substrate_type == "grid":
            grid_size = stratum.substrate.grid.size
            grid_dims_per_axis = stratum.substrate.grid.dimensions
            grid_encoding_dims = grid_size ** grid_dims_per_axis  # e.g., 8^2 = 64
        else:
            grid_encoding_dims = 0  # Non-grid substrates don't have grid encoding

        if grid_encoding_dims > 0:
            fields.append(ObservationField(
                name="obs_grid_encoding",
                start_index=offset,
                end_index=offset + grid_encoding_dims,
                dims=grid_encoding_dims,
                curriculum_active=is_active,
                description=f"{grid_size}x{grid_size} grid encoding" if is_active else "Masked (partial obs active)"
            ))
            offset += grid_encoding_dims

    # Partial vision (local window)
    if stratum.vision.support in ["both", "partial"]:
        is_active = (curriculum.active_vision == "partial")

        # Compute local window dimensions from normalized vision_range
        if stratum.substrate.substrate_type == "grid":
            grid_size = stratum.substrate.grid.size
            # vision_range is 0.0-1.0, represents fraction of grid
            # e.g., 0.625 on 8x8 grid = 5-cell window → 5x5 = 25 dims
            window_size = max(3, int(curriculum.vision_range * grid_size))
            # Force odd size (agent at center)
            if window_size % 2 == 0:
                window_size += 1
            # Clamp to grid size
            window_size = min(window_size, grid_size)

            local_window_dims = window_size ** 2  # e.g., 5^2 = 25
        else:
            local_window_dims = 0

        if local_window_dims > 0:
            fields.append(ObservationField(
                name="obs_local_window",
                start_index=offset,
                end_index=offset + local_window_dims,
                dims=local_window_dims,
                curriculum_active=is_active,
                description=f"{window_size}x{window_size} local window" if is_active else "Masked (global obs active)"
            ))
            offset += local_window_dims

    # ===== Position and Velocity (always active) =====

    position_dims = stratum.substrate.grid.dimensions  # 2 for Grid2D, 3 for Grid3D

    fields.append(ObservationField(
        name="obs_position",
        start_index=offset,
        end_index=offset + position_dims,
        dims=position_dims,
        curriculum_active=True,
        description=f"Agent position ({position_dims}D coordinates)"
    ))
    offset += position_dims

    fields.append(ObservationField(
        name="obs_velocity",
        start_index=offset,
        end_index=offset + position_dims,
        dims=position_dims,
        curriculum_active=True,
        description=f"Agent velocity ({position_dims}D vector)"
    ))
    offset += position_dims

    # ===== Meters (always active, fixed vocabulary) =====

    meter_count = len(environment.meters.meters)

    fields.append(ObservationField(
        name="obs_meters",
        start_index=offset,
        end_index=offset + meter_count,
        dims=meter_count,
        curriculum_active=True,
        description=f"{meter_count} meter values (normalized 0-1)"
    ))
    offset += meter_count

    # ===== Affordances (always active, fixed vocabulary) =====

    affordance_count = len(environment.affordances.affordances)

    fields.append(ObservationField(
        name="obs_affordances",
        start_index=offset,
        end_index=offset + affordance_count,
        dims=affordance_count,
        curriculum_active=True,
        description=f"{affordance_count} affordance distances (normalized)"
    ))
    offset += affordance_count

    # ===== Temporal Features (Support/Active pattern) =====

    if stratum.temporal.support:
        is_active = curriculum.active_temporal

        # Temporal features: (time_of_day_sin, time_of_day_cos, day_progress, is_night)
        temporal_dims = 4

        fields.append(ObservationField(
            name="obs_temporal",
            start_index=offset,
            end_index=offset + temporal_dims,
            dims=temporal_dims,
            curriculum_active=is_active,
            description="Temporal features (day/night cycle)" if is_active else "Masked (temporal inactive)"
        ))
        offset += temporal_dims

    # ===== Build ObservationSpec =====

    total_dims = offset
    active_dims = sum(f.dims for f in fields if f.curriculum_active)
    masked_dims = sum(f.dims for f in fields if not f.curriculum_active)

    obs_spec = ObservationSpec(
        fields=fields,
        total_dims=total_dims,
        curriculum_level=curriculum.version  # e.g., "1.0.0"
    )

    print(f"\n  Observation spec for curriculum {curriculum.version}:")
    print(f"    Total dims: {total_dims} (active: {active_dims}, masked: {masked_dims})")
    for field in fields:
        status = "ACTIVE" if field.curriculum_active else "MASKED"
        print(f"      [{field.start_index:3d}:{field.end_index:3d}] {field.name:25s} ({field.dims:3d} dims) {status}")

    return obs_spec
```

**Step 2: Test observation spec builder**

```bash
export PYTHONPATH=$(pwd)/src:$PYTHONPATH
python3 << 'PYTEST'
from pathlib import Path
from townlet.universe.compiler import _load_experiment_structure, _build_observation_spec

experiment_dir = Path("configs/default_curriculum")
(experiment, stratum, environment, actions, agent, levels_dict) = _load_experiment_structure(experiment_dir)

# Test L1 (global vision, no temporal)
curriculum_l1, bars_l1, affordances_l1, training_l1 = levels_dict["L1_full_observability"]

print("=== Testing L1 (global vision) ===")
obs_spec_l1 = _build_observation_spec(stratum, environment, curriculum_l1, agent)

# Verify structure
assert obs_spec_l1.total_dims > 0
grid_field = next((f for f in obs_spec_l1.fields if f.name == "obs_grid_encoding"), None)
assert grid_field is not None
assert grid_field.curriculum_active == True  # L1 uses global vision

print(f"\n✓ L1 obs_dim: {obs_spec_l1.total_dims}")
print("\nSUCCESS: Observation spec builder working")
PYTEST
```

Expected output: Shows L1 observation spec with grid_encoding ACTIVE

**Step 3: Commit observation spec builder**

```bash
git add src/townlet/universe/compiler.py
git commit -m "feat(compiler): add Stage 5 observation spec builder

- _build_observation_spec() implements Support/Active pattern
- Vision fields: stratum declares support, curriculum declares active
- Temporal fields: same pattern
- All fields included in obs_dim (masked fields zeroed for transfer learning)
- Tested on L1 config successfully"
```

### Task 4.7: Wire Stage 5 into compile_universe and return CompiledUniverse

**Files:**
- Modify: `src/townlet/universe/compiler.py` (update `compile_universe` to use Stage 5 and return result)
- Read: Check if `CompiledUniverse` class exists or needs creation

**Step 1: Check if CompiledUniverse exists**

```bash
export PYTHONPATH=$(pwd)/src:$PYTHONPATH
python3 << 'PYTEST'
try:
    from townlet.universe.compiled import CompiledUniverse
    import inspect

    print("CompiledUniverse found:")
    print(f"  Module: {CompiledUniverse.__module__}")

    # Show __init__ signature
    sig = inspect.signature(CompiledUniverse.__init__)
    print(f"  __init__ signature: {sig}")

    # List attributes
    if hasattr(CompiledUniverse, '__annotations__'):
        print(f"  Attributes: {list(CompiledUniverse.__annotations__.keys())}")

except ImportError as e:
    print(f"CompiledUniverse not found: {e}")
    print("Will need to create minimal class for v2.1")
PYTEST
```

Expected output: Either shows existing CompiledUniverse or indicates need to create it

**Step 2: Create/update CompiledUniverse for v2.1 (if needed)**

If CompiledUniverse doesn't exist or needs updating, create minimal version:

```bash
# Only run if CompiledUniverse needs creation
cat > src/townlet/universe/compiled.py << 'EOF'
"""CompiledUniverse for v2.1 hierarchical config structure."""

from dataclasses import dataclass
from typing import Dict, Tuple
from pathlib import Path

from townlet.config.experiment_config import ExperimentConfig
from townlet.config.stratum_config import StratumConfig
from townlet.config.environment_config import EnvironmentConfig
from townlet.config.actions_config import ActionsConfig
from townlet.config.agent_config import AgentConfig
from townlet.config.curriculum_config import CurriculumConfig
from townlet.config.bars_config import BarsConfig
from townlet.config.affordances_config import AffordancesConfig
from townlet.config.training_config import TrainingConfig
from townlet.vfs.observation_builder import ObservationSpec


@dataclass
class CompiledUniverse:
    """
    Compiled universe for v2.1 hierarchical config structure.

    Contains all loaded and validated configuration plus derived metadata.
    """
    # Shared configs
    experiment: ExperimentConfig
    stratum: StratumConfig
    environment: EnvironmentConfig
    actions: ActionsConfig
    agent: AgentConfig

    # Curriculum levels: {level_name: (curriculum, bars, affordances, training)}
    curriculum_levels: Dict[str, Tuple[CurriculumConfig, BarsConfig, AffordancesConfig, TrainingConfig]]

    # Derived metadata (per level)
    observation_specs: Dict[str, ObservationSpec]  # {level_name: obs_spec}

    # Provenance
    experiment_dir: Path

    def get_level(self, level_name: str) -> Tuple[CurriculumConfig, BarsConfig, AffordancesConfig, TrainingConfig]:
        """Get curriculum level configs by name."""
        if level_name not in self.curriculum_levels:
            available = list(self.curriculum_levels.keys())
            raise ValueError(f"Level '{level_name}' not found. Available: {available}")
        return self.curriculum_levels[level_name]

    def get_obs_spec(self, level_name: str) -> ObservationSpec:
        """Get observation spec for curriculum level."""
        if level_name not in self.observation_specs:
            available = list(self.observation_specs.keys())
            raise ValueError(f"Obs spec for '{level_name}' not found. Available: {available}")
        return self.observation_specs[level_name]
EOF

python3 -m py_compile src/townlet/universe/compiled.py
echo "Created CompiledUniverse class"
```

**Step 3: Update compile_universe to build obs specs and return**

Update the `compile_universe` function body:

```python
def compile_universe(experiment_dir: Path) -> CompiledUniverse:
    """[docstring from Task 4.2]"""

    print(f"Compiling experiment: {experiment_dir}")

    # Stage 1: Load hierarchical structure
    print("\n=== Stage 1: Loading hierarchical config structure ===")
    (experiment, stratum, environment, actions, agent, levels_dict) = _load_experiment_structure(experiment_dir)

    print(f"\nLoaded experiment: '{experiment.metadata.name}'")
    print(f"  Description: {experiment.metadata.description}")
    print(f"  Stratum: {stratum.substrate.substrate_type} ({stratum.substrate.grid.size}x{stratum.substrate.grid.size})")
    print(f"  Curriculum levels: {list(levels_dict.keys())}")

    # Stage 2: Cross-curriculum vocabulary validation
    print("\n=== Stage 2: Validating vocabulary consistency ===")
    _validate_vocabulary_consistency(environment, levels_dict)

    # Stage 3-4: Symbol table and resolution
    # TODO: Implement if needed for your system
    # For now, skip these stages (legacy may not need them)
    print("\n=== Stage 3-4: Symbol table and resolution (skipped) ===")

    # Stage 5: Build observation specs for all curriculum levels
    print("\n=== Stage 5: Building observation specs ===")
    observation_specs = {}
    for level_name, (curriculum, bars, affordances, training) in levels_dict.items():
        print(f"\nBuilding obs spec for {level_name}:")
        obs_spec = _build_observation_spec(stratum, environment, curriculum, agent)
        observation_specs[level_name] = obs_spec

    # Stage 6-7: Optimization and emit
    print("\n=== Stage 6-7: Optimization and emit ===")
    print("Creating CompiledUniverse...")

    from townlet.universe.compiled import CompiledUniverse

    compiled = CompiledUniverse(
        experiment=experiment,
        stratum=stratum,
        environment=environment,
        actions=actions,
        agent=agent,
        curriculum_levels=levels_dict,
        observation_specs=observation_specs,
        experiment_dir=experiment_dir
    )

    print(f"\n✓ Compilation complete for '{experiment.metadata.name}'")
    print(f"  {len(compiled.curriculum_levels)} curriculum levels")
    print(f"  {len(compiled.observation_specs)} observation specs generated")

    return compiled
```

**Step 4: Test full compilation**

```bash
export PYTHONPATH=$(pwd)/src:$PYTHONPATH
python3 << 'PYTEST'
from pathlib import Path
from townlet.universe.compiler import compile_universe

compiled = compile_universe(Path("configs/default_curriculum"))

print(f"\n✓ Compiled: {compiled.experiment.metadata.name}")
print(f"✓ Levels: {list(compiled.curriculum_levels.keys())}")
print(f"✓ Obs specs: {list(compiled.observation_specs.keys())}")

# Test accessor methods
curriculum, bars, affordances, training = compiled.get_level("L1_full_observability")
print(f"✓ L1 curriculum: {curriculum.active_vision}")

obs_spec = compiled.get_obs_spec("L1_full_observability")
print(f"✓ L1 obs_dim: {obs_spec.total_dims}")

print("\nSUCCESS: Full compilation working!")
PYTEST
```

Expected output: Compiles successfully, returns CompiledUniverse with all levels

**Step 5: Commit Phase 4 completion**

```bash
git add src/townlet/universe/compiler.py src/townlet/universe/compiled.py
git commit -m "feat(compiler): complete Phase 4 - v2.1 compilation working

Phase 4 complete:
- Stage 1: Load hierarchical structure (5 shared + N curriculum)
- Stage 2: Vocabulary validation (WHAT vs HOW enforcement)
- Stage 3-4: Skipped (not needed for v2.1)
- Stage 5: Observation specs with Support/Active pattern
- Stage 6-7: Return CompiledUniverse

Compiler now fully supports v2.1 hierarchical config structure.
All 5 curriculum levels compile successfully."
```

**Phase 4 Complete!** Compiler updated for v2.1 structure.

---

## Phase 5: Test Updates (2-3 hours)

### Task 5.1: Capture test baseline and analyze failures

**Files:**
- Create: `test_failures_baseline.txt` (test results before fixes)
- Create: `docs/bugs/BUNDLE-01-curriculum-observation-architecture/test-fix-strategy.md`

**Step 1: Run test suite and capture all failures**

```bash
UV_CACHE_DIR=.uv-cache PYTHONPATH=$(pwd)/src uv run pytest tests/test_townlet/ -v --tb=short > test_failures_baseline.txt 2>&1
echo "Exit code: $?" >> test_failures_baseline.txt

# Show summary
tail -30 test_failures_baseline.txt
```

Expected output: Shows test failures (likely FileNotFoundError, AttributeError, AssertionError)

**Step 2: Categorize failures by error type**

```bash
python3 << 'PYTEST'
import re
from collections import defaultdict

with open("test_failures_baseline.txt") as f:
    content = f.read()

# Extract FAILED lines
failed_pattern = r'FAILED (tests/[^\s]+)::(test_\w+) - (.+?)(?:\n|$)'
failures = re.findall(failed_pattern, content)

# Categorize by error type
categories = defaultdict(list)
for test_file, test_name, error in failures:
    # Extract error type (first word before colon or space)
    error_type = error.split(':')[0].split()[0] if error else "Unknown"
    categories[error_type].append(f"{test_file}::{test_name}")

# Print categories
print("=" * 60)
print("FAILURE CATEGORIES")
print("=" * 60)

total_failures = sum(len(tests) for tests in categories.values())
print(f"\nTotal failures: {total_failures}")
print(f"Categories: {len(categories)}\n")

for error_type in sorted(categories.keys(), key=lambda k: -len(categories[k])):
    tests = categories[error_type]
    print(f"\n{error_type} ({len(tests)} failures)")
    print("-" * 60)
    for test in tests[:5]:  # Show first 5
        print(f"  {test}")
    if len(tests) > 5:
        print(f"  ... and {len(tests) - 5} more")

# Save categories to file
with open("test_failure_categories.txt", "w") as f:
    f.write("FAILURE CATEGORIES\n")
    f.write("=" * 60 + "\n\n")
    f.write(f"Total failures: {total_failures}\n")
    f.write(f"Categories: {len(categories)}\n\n")

    for error_type in sorted(categories.keys(), key=lambda k: -len(categories[k])):
        tests = categories[error_type]
        f.write(f"\n{error_type} ({len(tests)} failures)\n")
        f.write("-" * 60 + "\n")
        for test in tests:
            f.write(f"  {test}\n")

print("\n✓ Saved to test_failure_categories.txt")
PYTEST
```

Expected output: Categorized list of failures (FileNotFoundError, AttributeError, AssertionError, etc.)

**Step 3: Create test fix strategy document**

```bash
cat > docs/bugs/BUNDLE-01-curriculum-observation-architecture/test-fix-strategy.md << 'EOF'
# Test Fix Strategy for Config v2.1 Migration

**Date**: 2025-11-15
**Phase**: 5 - Test Updates

## Failure Categories

[See test_failure_categories.txt for complete list]

Common patterns expected:
1. **FileNotFoundError**: Tests loading `config_dir/substrate.yaml` (flat) instead of `experiment_dir/stratum.yaml` (hierarchical)
2. **AttributeError**: Tests expecting single config object instead of CompiledUniverse
3. **AssertionError**: Tests with hardcoded obs_dim calculations that don't account for Support/Active masking

## Fix Strategy

For each category:
1. Fix one representative test (establish pattern)
2. Verify fix works (test passes)
3. Apply pattern to all tests in category (batch fix)
4. Commit batch with clear message

## Fix Patterns

### Pattern 1: Config Path Updates (FileNotFoundError)

```python
# OLD (flat structure)
config_dir = Path("configs/L1_full_observability")
substrate_config = SubstrateConfig.from_yaml(config_dir / "substrate.yaml")

# NEW (hierarchical structure)
from townlet.universe.compiler import compile_universe
compiled = compile_universe(Path("configs/default_curriculum"))
stratum = compiled.stratum
substrate_config = stratum.substrate
```

### Pattern 2: Use CompiledUniverse (AttributeError)

```python
# OLD (direct config loading)
bars_config = BarsConfig.from_yaml(config_dir / "bars.yaml")

# NEW (from compiled universe)
compiled = compile_universe(Path("configs/default_curriculum"))
curriculum, bars, affordances, training = compiled.get_level("L1_full_observability")
```

### Pattern 3: Use ObservationSpec (AssertionError on obs_dim)

```python
# OLD (hardcoded calculation)
expected_dim = 64 + 2 + 2 + 8 + 15 + 4

# NEW (from observation spec)
obs_spec = compiled.get_obs_spec("L1_full_observability")
expected_dim = obs_spec.total_dims
```

## Tracking

- [ ] Category 1: FileNotFoundError (config paths) - XX tests
- [ ] Category 2: AttributeError (missing config objects) - XX tests
- [ ] Category 3: AssertionError (obs_dim) - XX tests
- [ ] Category 4: Other failures - XX tests
- [ ] All tests passing

## Notes

- Fix incrementally, commit frequently
- Use `pytest -k <test_name>` to test individual fixes
- Mark each category complete as you go
EOF

cat docs/bugs/BUNDLE-01-curriculum-observation-architecture/test-fix-strategy.md
```

**Step 4: Commit baseline**

```bash
git add test_failures_baseline.txt test_failure_categories.txt docs/bugs/BUNDLE-01-curriculum-observation-architecture/test-fix-strategy.md
git commit -m "test: capture Phase 5 baseline and categorize failures

- Ran full test suite, captured failures
- Categorized by error type (FileNotFoundError, AttributeError, etc.)
- Created fix strategy document with patterns
- Ready to begin incremental fixes"
```

### Task 5.2: Fix Category 1 representative - Config path (FileNotFoundError)

**Files:**
- Identify and modify one test file with FileNotFoundError

**Step 1: Find representative test**

```bash
# Find first test with FileNotFoundError on substrate.yaml
grep -n "substrate.yaml" test_failures_baseline.txt | head -1
```

Note the test file and function name from output.

**Step 2: Read the failing test**

```bash
# Replace with actual test file found above
# Example: tests/test_townlet/unit/substrate/test_grid_substrate.py
grep -A 20 "def test_" tests/test_townlet/unit/substrate/test_grid_substrate.py | head -25
```

**Step 3: Fix the test using Pattern 1**

Example fix (adapt to actual test):

```python
# Before (in the test file)
def test_grid_substrate_initialization():
    config_dir = Path("configs/L1_full_observability")
    substrate_config = SubstrateConfig.from_yaml(config_dir / "substrate.yaml")

    substrate = Grid2DSubstrate(substrate_config)
    assert substrate.grid_size == 8

# After
def test_grid_substrate_initialization():
    from townlet.universe.compiler import compile_universe

    compiled = compile_universe(Path("configs/default_curriculum"))
    stratum = compiled.stratum
    substrate_config = stratum.substrate

    substrate = Grid2DSubstrate(substrate_config)
    assert substrate.grid_size == 8
```

**Step 4: Test the fix**

```bash
# Replace with actual test path
UV_CACHE_DIR=.uv-cache PYTHONPATH=$(pwd)/src uv run pytest tests/test_townlet/unit/substrate/test_grid_substrate.py::test_grid_substrate_initialization -v
```

Expected output: Test passes

**Step 5: Commit single fix (establish pattern)**

```bash
git add tests/test_townlet/unit/substrate/test_grid_substrate.py
git commit -m "test: fix representative FileNotFoundError test (config path)

- Updated test_grid_substrate_initialization to use compile_universe
- Pattern: config_dir/substrate.yaml → compiled.stratum.substrate
- Test now passes, establishes pattern for Category 1 fixes"
```

### Task 5.3: Apply Category 1 fix pattern to all similar tests

**Files:**
- Modify all tests with similar FileNotFoundError pattern

**Step 1: Find all tests loading substrate.yaml**

```bash
grep -r "substrate\.yaml" tests/test_townlet/ --include="*.py" -l
```

Note: This shows files, not specific test functions.

**Step 2: Apply pattern to each file**

For each file found, update all tests following Pattern 1:
- Replace `config_dir / "substrate.yaml"` → `compile_universe(...).stratum.substrate`
- Replace `config_dir / "bars.yaml"` → `compile_universe(...).get_level(...)[1]` (bars is index 1)
- etc.

**Step 3: Test batch of fixes**

```bash
# Test all files you modified
UV_CACHE_DIR=.uv-cache PYTHONPATH=$(pwd)/src uv run pytest tests/test_townlet/unit/substrate/ -v
```

Expected output: All substrate tests pass

**Step 4: Commit Category 1 batch**

```bash
git add tests/test_townlet/
git commit -m "test: fix all Category 1 failures (config path → hierarchical)

Applied Pattern 1 to all tests:
- substrate.yaml → compile_universe().stratum.substrate
- bars.yaml → compile_universe().get_level(...)[1]
- affordances.yaml → compile_universe().get_level(...)[2]
- training.yaml → compile_universe().get_level(...)[3]

All tests now use hierarchical v2.1 structure.
Category 1 complete (XX tests fixed)."
```

### Task 5.4: Fix Category 2 representative - Missing config object (AttributeError)

**Files:**
- Identify and modify one test file with AttributeError

**Step 1: Find representative test**

```bash
grep -n "AttributeError" test_failures_baseline.txt | head -1
```

**Step 2: Fix using Pattern 2**

Example:

```python
# Before
def test_bar_depletion():
    bars_config = BarsConfig.from_yaml(config_dir / "bars.yaml")
    assert bars_config.bars[0].name == "energy"

# After
def test_bar_depletion():
    from townlet.universe.compiler import compile_universe

    compiled = compile_universe(Path("configs/default_curriculum"))
    curriculum, bars, affordances, training = compiled.get_level("L1_full_observability")

    assert bars.bars[0].name == "energy"
```

**Step 3-5: Test, apply to category, commit**

(Same pattern as Task 5.2-5.3)

### Task 5.5: Fix Category 3 representative - obs_dim calculations (AssertionError)

**Files:**
- Identify and modify tests with hardcoded obs_dim

**Step 1: Find representative test**

```bash
grep -n "obs_dim" test_failures_baseline.txt | head -1
```

**Step 2: Fix using Pattern 3**

Example:

```python
# Before
def test_observation_dimensions():
    expected_dim = 64 + 2 + 2 + 8 + 15 + 4  # hardcoded
    assert env.obs_dim == expected_dim

# After
def test_observation_dimensions():
    from townlet.universe.compiler import compile_universe

    compiled = compile_universe(Path("configs/default_curriculum"))
    obs_spec = compiled.get_obs_spec("L1_full_observability")

    assert env.obs_dim == obs_spec.total_dims

    # If you need to verify specific fields:
    grid_field = next(f for f in obs_spec.fields if f.name == "obs_grid_encoding")
    assert grid_field.dims == 64
    assert grid_field.curriculum_active == True
```

**Step 3-5: Test, apply to category, commit**

(Same pattern as Task 5.2-5.3)

### Task 5.6: Verify all tests passing

**Files:**
- Update: `docs/bugs/BUNDLE-01-curriculum-observation-architecture/test-fix-strategy.md`

**Step 1: Run full test suite**

```bash
UV_CACHE_DIR=.uv-cache PYTHONPATH=$(pwd)/src uv run pytest tests/test_townlet/ -v --tb=short
```

Expected output: All 144 tests pass (or note which still fail)

**Step 2: Update test fix strategy with results**

```bash
# Mark categories complete in test-fix-strategy.md
# Update tracking section with checkmarks
```

**Step 3: Commit Phase 5 completion**

```bash
git add tests/test_townlet/ docs/bugs/BUNDLE-01-curriculum-observation-architecture/test-fix-strategy.md
git commit -m "test: Phase 5 complete - all tests passing with v2.1 config

Summary:
- Category 1: XX tests fixed (config path → hierarchical)
- Category 2: XX tests fixed (direct load → CompiledUniverse)
- Category 3: XX tests fixed (hardcoded obs_dim → ObservationSpec)

All 144 tests now use v2.1 config structure and pass successfully."
```

**Phase 5 Complete!** All tests passing with v2.1 config.

---

## Phase 6: Remaining Curriculum Levels (1-2 hours)

### Task 6.1: Extract L0_0_minimal configs from reference

**Files:**
- Create: `configs/default_curriculum/levels/L0_0_minimal/curriculum.yaml`
- Create: `configs/default_curriculum/levels/L0_0_minimal/bars.yaml`
- Create: `configs/default_curriculum/levels/L0_0_minimal/affordances.yaml`
- Create: `configs/default_curriculum/levels/L0_0_minimal/training.yaml`

**Step 1: Create directory**

```bash
mkdir -p configs/default_curriculum/levels/L0_0_minimal
```

**Step 2: Create curriculum.yaml**

```bash
cat > configs/default_curriculum/levels/L0_0_minimal/curriculum.yaml << 'EOF'
version: "1.0.0"

# L0_0: Minimal temporal credit assignment
# 3×3 grid, 1 bar (energy), 1 affordance (RECHARGE)
# Focus: Learn that RECHARGE increases energy (basic credit assignment)

active_vision: global       # Full grid observable
active_temporal: false      # No time-based dynamics
vision_range: 1.0           # Full grid (though only 3×3)
day_length: null            # No temporal mechanics
EOF
```

**Step 3: Create bars.yaml (energy only)**

```bash
cat > configs/default_curriculum/levels/L0_0_minimal/bars.yaml << 'EOF'
bars:
  - name: energy
    depletion_rate: 0.01
    depletion_type: constant
    depletion_variance: 0.0
    critical_threshold: 0.2

    ranges:
      healthy: [0.5, 1.0]
      moderate: [0.2, 0.5]
      critical: [0.0, 0.2]

    cascades:
      - target: energy        # Self-referential (no cross-bar cascades)
        strength: 0.0
        threshold: 0.0
        effect_type: proportional
EOF
```

**Step 4: Create affordances.yaml (RECHARGE only)**

```bash
cat > configs/default_curriculum/levels/L0_0_minimal/affordances.yaml << 'EOF'
affordances:
  - name: RECHARGE
    max_instances: 3

    effects:
      - bar: energy
        delta: 0.5
        delta_type: absolute

    costs: []
    preconditions: []

    interaction_radius: 1.0
    respawn: true
    respawn_turns: 20
EOF
```

**Step 5: Create training.yaml (same as L1)**

```bash
cat > configs/default_curriculum/levels/L0_0_minimal/training.yaml << 'EOF'
episodes: 10000
max_steps_per_episode: 1000
batch_size: 32
target_update_frequency: 500
use_double_dqn: false
gradient_clip_max_norm: 10.0

learning_rate: 0.0001
gamma: 0.99
replay_buffer_capacity: 100000
num_agents: 256

curriculum:
  strategy: static

static_curriculum: {}
adversarial_curriculum: {}

exploration:
  strategy: adaptive_rnd
  epsilon_greedy: {}
  rnd: {}
  adaptive_rnd:
    initial_weight: 0.1
    min_weight: 0.001
    annealing_threshold: 100.0

checkpoint:
  save_frequency: 1000
  keep_last_n: 5
EOF
```

**Step 6: Test L0_0 compiles**

```bash
export PYTHONPATH=$(pwd)/src:$PYTHONPATH
python3 << 'PYTEST'
from pathlib import Path
from townlet.universe.compiler import compile_universe

compiled = compile_universe(Path("configs/default_curriculum"))

# Verify L0_0 exists
assert "L0_0_minimal" in compiled.curriculum_levels
curriculum, bars, affordances, training = compiled.get_level("L0_0_minimal")

print(f"✓ L0_0_minimal compiled successfully")
print(f"  Bars: {[b.name for b in bars.bars]}")
print(f"  Affordances: {[a.name for a in affordances.affordances]}")
print(f"  Active vision: {curriculum.active_vision}")

# Verify content
assert len(bars.bars) == 1
assert bars.bars[0].name == "energy"
assert len(affordances.affordances) == 1
assert affordances.affordances[0].name == "RECHARGE"

# Check obs spec
obs_spec = compiled.get_obs_spec("L0_0_minimal")
print(f"  obs_dim: {obs_spec.total_dims}")

print("\nSUCCESS: L0_0_minimal working!")
PYTEST
```

Expected output: L0_0 compiles with 1 bar, 1 affordance

**Step 7: Commit L0_0**

```bash
git add configs/default_curriculum/levels/L0_0_minimal/
git commit -m "feat(config): add L0_0_minimal v2.1 curriculum level

- Temporal credit assignment level (3×3 grid, 1 affordance)
- Only energy meter + RECHARGE affordance
- Full observability, no temporal mechanics
- Compiles successfully, obs spec generated"
```

### Task 6.2: Extract L0_5_dual_resource configs from reference

**Files:**
- Create: `configs/default_curriculum/levels/L0_5_dual_resource/*.yaml` (4 files)

**Step 1: Create directory and curriculum.yaml**

```bash
mkdir -p configs/default_curriculum/levels/L0_5_dual_resource

cat > configs/default_curriculum/levels/L0_5_dual_resource/curriculum.yaml << 'EOF'
version: "1.0.0"

# L0_5: Dual resource management
# 7×7 grid, 2 bars (energy, health), 4 affordances
# Focus: Learn cascade effects (energy depletion → health drain)

active_vision: global
active_temporal: false
vision_range: 1.0
day_length: null
EOF
```

**Step 2: Create bars.yaml (energy + health with cascade)**

```bash
cat > configs/default_curriculum/levels/L0_5_dual_resource/bars.yaml << 'EOF'
bars:
  - name: energy
    depletion_rate: 0.008
    depletion_type: constant
    depletion_variance: 0.0
    critical_threshold: 0.2

    ranges:
      healthy: [0.5, 1.0]
      moderate: [0.2, 0.5]
      critical: [0.0, 0.2]

    cascades:
      - target: health        # Energy → health cascade
        strength: 0.3
        threshold: 0.3
        effect_type: proportional

  - name: health
    depletion_rate: 0.005
    depletion_type: constant
    depletion_variance: 0.0
    critical_threshold: 0.2

    ranges:
      healthy: [0.5, 1.0]
      moderate: [0.2, 0.5]
      critical: [0.0, 0.2]

    cascades:
      - target: health        # Self-referential
        strength: 0.0
        threshold: 0.0
        effect_type: proportional
EOF
```

**Step 3: Create affordances.yaml (4 affordances)**

```bash
cat > configs/default_curriculum/levels/L0_5_dual_resource/affordances.yaml << 'EOF'
affordances:
  - name: RECHARGE
    max_instances: 3
    effects:
      - bar: energy
        delta: 0.4
        delta_type: absolute
    costs: []
    preconditions: []
    interaction_radius: 1.0
    respawn: true
    respawn_turns: 25

  - name: HEAL
    max_instances: 2
    effects:
      - bar: health
        delta: 0.35
        delta_type: absolute
    costs: []
    preconditions: []
    interaction_radius: 1.0
    respawn: true
    respawn_turns: 30

  - name: REST
    max_instances: 2
    effects:
      - bar: energy
        delta: 0.2
        delta_type: absolute
      - bar: health
        delta: 0.15
        delta_type: absolute
    costs: []
    preconditions: []
    interaction_radius: 1.0
    respawn: true
    respawn_turns: 40

  - name: WORK
    max_instances: 2
    effects: []
    costs:
      - bar: energy
        amount: 0.15
    preconditions:
      - bar: energy
        threshold: 0.2
        comparison: greater_than
    interaction_radius: 1.0
    respawn: true
    respawn_turns: 20
EOF
```

**Step 4: Copy training.yaml from L0_0**

```bash
cp configs/default_curriculum/levels/L0_0_minimal/training.yaml \
   configs/default_curriculum/levels/L0_5_dual_resource/training.yaml
```

**Step 5-6: Test and commit**

(Same as Task 6.1 steps 6-7, verify 2 bars and 4 affordances)

```bash
git add configs/default_curriculum/levels/L0_5_dual_resource/
git commit -m "feat(config): add L0_5_dual_resource v2.1 curriculum level

- Dual resource management (7×7 grid, 4 affordances)
- Energy + health meters with cascade effect
- RECHARGE, HEAL, REST, WORK affordances
- Full observability, no temporal mechanics"
```

### Task 6.3: Extract L2_partial_observability configs from reference

**Files:**
- Create: `configs/default_curriculum/levels/L2_partial_observability/*.yaml`

**Step 1: Copy from L1 and modify curriculum.yaml**

```bash
mkdir -p configs/default_curriculum/levels/L2_partial_observability

# Copy all 4 files from L1
cp configs/default_curriculum/levels/L1_full_observability/*.yaml \
   configs/default_curriculum/levels/L2_partial_observability/

# Update curriculum.yaml for partial observability
cat > configs/default_curriculum/levels/L2_partial_observability/curriculum.yaml << 'EOF'
version: "1.0.0"

# L2: Partial observability (POMDP)
# 8×8 grid, full vocabulary (8 bars, 14 affordances)
# 5×5 local window (vision_range=0.625 on 8×8 grid)
# Requires LSTM for memory (implemented in RecurrentSpatialQNetwork)

active_vision: partial      # Local window only
active_temporal: false
vision_range: 0.625         # 5-cell window on 8×8 grid
day_length: null
EOF
```

**Step 2: Verify bars.yaml and affordances.yaml match L1**

```bash
# These should be identical to L1 (same vocabulary)
diff configs/default_curriculum/levels/L1_full_observability/bars.yaml \
     configs/default_curriculum/levels/L2_partial_observability/bars.yaml

diff configs/default_curriculum/levels/L1_full_observability/affordances.yaml \
     configs/default_curriculum/levels/L2_partial_observability/affordances.yaml
```

Expected output: No differences (same vocabulary)

**Step 3: Test L2 compiles with correct obs spec**

```bash
export PYTHONPATH=$(pwd)/src:$PYTHONPATH
python3 << 'PYTEST'
from pathlib import Path
from townlet.universe.compiler import compile_universe

compiled = compile_universe(Path("configs/default_curriculum"))

curriculum_l2, bars_l2, affordances_l2, training_l2 = compiled.get_level("L2_partial_observability")

print(f"✓ L2_partial_observability compiled")
print(f"  Active vision: {curriculum_l2.active_vision}")
print(f"  Vision range: {curriculum_l2.vision_range}")

obs_spec_l2 = compiled.get_obs_spec("L2_partial_observability")
print(f"  obs_dim: {obs_spec_l2.total_dims}")

# Verify local window is ACTIVE, grid encoding is MASKED
local_window = next(f for f in obs_spec_l2.fields if f.name == "obs_local_window")
grid_encoding = next(f for f in obs_spec_l2.fields if f.name == "obs_grid_encoding")

assert local_window.curriculum_active == True   # Partial obs uses local window
assert grid_encoding.curriculum_active == False  # Grid encoding masked

print(f"  Local window: {local_window.dims} dims (ACTIVE)")
print(f"  Grid encoding: {grid_encoding.dims} dims (MASKED)")

print("\nSUCCESS: L2 POMDP working!")
PYTEST
```

Expected output: L2 compiles with local_window ACTIVE, grid_encoding MASKED

**Step 4: Commit L2**

```bash
git add configs/default_curriculum/levels/L2_partial_observability/
git commit -m "feat(config): add L2_partial_observability v2.1 curriculum level

- POMDP with 5×5 local window (vision_range=0.625)
- Same vocabulary as L1 (8 bars, 14 affordances)
- Observation spec: local_window ACTIVE, grid_encoding MASKED
- Enables transfer learning from L1 (same obs_dim, different active fields)"
```

### Task 6.4: Extract L3_temporal_mechanics configs from reference

**Files:**
- Create: `configs/default_curriculum/levels/L3_temporal_mechanics/*.yaml`

**Step 1: Copy from L1 and modify curriculum.yaml**

```bash
mkdir -p configs/default_curriculum/levels/L3_temporal_mechanics

# Copy all 4 files from L1
cp configs/default_curriculum/levels/L1_full_observability/*.yaml \
   configs/default_curriculum/levels/L3_temporal_mechanics/

# Update curriculum.yaml for temporal mechanics
cat > configs/default_curriculum/levels/L3_temporal_mechanics/curriculum.yaml << 'EOF'
version: "1.0.0"

# L3: Temporal mechanics (day/night cycle)
# 8×8 grid, full vocabulary (8 bars, 14 affordances)
# 24-tick day/night cycle affects affordance behavior
# Adds temporal features to observation (time_of_day, day_progress, is_night)

active_vision: global
active_temporal: true       # Temporal features active
vision_range: 1.0
day_length: 24              # 24 ticks per day
EOF
```

**Step 2: Test L3 compiles with temporal features**

```bash
export PYTHONPATH=$(pwd)/src:$PYTHONPATH
python3 << 'PYTEST'
from pathlib import Path
from townlet.universe.compiler import compile_universe

compiled = compile_universe(Path("configs/default_curriculum"))

curriculum_l3, bars_l3, affordances_l3, training_l3 = compiled.get_level("L3_temporal_mechanics")

print(f"✓ L3_temporal_mechanics compiled")
print(f"  Active temporal: {curriculum_l3.active_temporal}")
print(f"  Day length: {curriculum_l3.day_length}")

obs_spec_l3 = compiled.get_obs_spec("L3_temporal_mechanics")
print(f"  obs_dim: {obs_spec_l3.total_dims}")

# Verify temporal features are ACTIVE
temporal = next(f for f in obs_spec_l3.fields if f.name == "obs_temporal")
assert temporal.curriculum_active == True

print(f"  Temporal features: {temporal.dims} dims (ACTIVE)")

print("\nSUCCESS: L3 temporal mechanics working!")
PYTEST
```

Expected output: L3 compiles with temporal features ACTIVE

**Step 3: Commit L3**

```bash
git add configs/default_curriculum/levels/L3_temporal_mechanics/
git commit -m "feat(config): add L3_temporal_mechanics v2.1 curriculum level

- 24-tick day/night cycle (day_length=24)
- Same vocabulary as L1 (8 bars, 14 affordances)
- Temporal features ACTIVE (time_of_day, day_progress, is_night)
- Full observability with temporal context"
```

### Task 6.5: Verify all 5 levels compile with consistent obs_dim

**Files:**
- None (verification only)

**Step 1: Compile all levels and check obs specs**

```bash
export PYTHONPATH=$(pwd)/src:$PYTHONPATH
python3 << 'PYTEST'
from pathlib import Path
from townlet.universe.compiler import compile_universe

compiled = compile_universe(Path("configs/default_curriculum"))

print("=" * 70)
print("ALL CURRICULUM LEVELS - OBSERVATION SPECS")
print("=" * 70)

for level_name in sorted(compiled.curriculum_levels.keys()):
    curriculum, bars, affordances, training = compiled.get_level(level_name)
    obs_spec = compiled.get_obs_spec(level_name)

    active_dims = sum(f.dims for f in obs_spec.fields if f.curriculum_active)
    masked_dims = sum(f.dims for f in obs_spec.fields if not f.curriculum_active)

    print(f"\n{level_name}")
    print(f"  Vision: {curriculum.active_vision:8s}  Temporal: {str(curriculum.active_temporal):5s}")
    print(f"  Bars: {len(bars.bars):2d}  Affordances: {len(affordances.affordances):2d}")
    print(f"  obs_dim: {obs_spec.total_dims:3d} (active: {active_dims:3d}, masked: {masked_dims:3d})")

print("\n" + "=" * 70)
print("✓ All 5 curriculum levels compiled successfully")
print("✓ Vocabulary consistent across all levels")
print("=" * 70)
PYTEST
```

Expected output: Shows all 5 levels with their obs_dim, active/masked breakdown

**Step 2: Commit Phase 6 completion**

```bash
git commit --allow-empty -m "feat(config): Phase 6 complete - all 5 curriculum levels migrated

All curriculum levels now using v2.1 hierarchical structure:
- L0_0_minimal: 1 bar, 1 affordance (temporal credit assignment)
- L0_5_dual_resource: 2 bars, 4 affordances (cascade effects)
- L1_full_observability: 8 bars, 14 affordances (baseline)
- L2_partial_observability: 8 bars, 14 affordances (POMDP with local window)
- L3_temporal_mechanics: 8 bars, 14 affordances (day/night cycle)

Vocabulary consistent across all levels.
Observation specs generated with Support/Active pattern.
Ready for Phase 7 (cleanup and merge)."
```

**Phase 6 Complete!** All 5 curriculum levels migrated to v2.1.

---

## Phase 7: Cleanup & Validation (30 minutes)

### Task 7.1: Final test suite validation

**Files:**
- None (verification only)

**Step 1: Run full test suite one final time**

```bash
UV_CACHE_DIR=.uv-cache PYTHONPATH=$(pwd)/src uv run pytest tests/test_townlet/ -v --tb=short | tee final_test_results.txt
```

Expected output: All 144 tests pass

**Step 2: Run training smoke test on each level**

```bash
for level in L0_0_minimal L0_5_dual_resource L1_full_observability L2_partial_observability L3_temporal_mechanics; do
    echo "================================"
    echo "Smoke testing: $level"
    echo "================================"

    timeout 30 bash -c "
        export UV_CACHE_DIR=.uv-cache
        export PYTHONPATH=$(pwd)/src
        uv run python scripts/run_demo.py \
            --config configs/default_curriculum \
            --level $level \
            --episodes 10 \
            2>&1 | tail -20
    "

    if [ $? -eq 0 ]; then
        echo "✓ $level: PASS"
    else
        echo "✗ $level: FAIL (check output above)"
    fi
    echo ""
done
```

Expected output: Each level runs for 10 episodes without crashes

**Step 3: Verify no compilation errors**

```bash
python3 -m py_compile src/townlet/universe/compiler.py
python3 -m py_compile src/townlet/universe/compiled.py
python3 -m py_compile src/townlet/config/*.py

echo "✓ All Python files compile successfully"
```

No commit yet - just validation.

### Task 7.2: Remove archived configs

**Files:**
- Delete: `configs_archive/` directory

**Step 1: Verify no references to archived configs**

```bash
# Check for any hardcoded references to old flat structure
grep -r "configs/L[0-9]" src/ tests/ --include="*.py" | grep -v "default_curriculum" || echo "✓ No flat config references in code"

# Check for references to configs_archive
grep -r "configs_archive" src/ tests/ --include="*.py" || echo "✓ No archive references in code"
```

Expected output: No references found (good!)

**Step 2: Delete archived configs**

```bash
rm -rf configs_archive/

git status
```

Expected output: Shows `configs_archive/` deleted

**Step 3: Commit archive removal**

```bash
git add -A
git commit -m "chore: remove archived v1 flat configs

All configs migrated to v2.1 hierarchical structure:
  configs/default_curriculum/
  ├── experiment.yaml
  ├── stratum.yaml
  ├── environment.yaml
  ├── actions.yaml
  ├── agent.yaml
  └── levels/L*/

Old flat configs (configs/L*/*.yaml) archived then deleted.
No code references to old structure remain."
```

### Task 7.3: Update documentation

**Files:**
- Modify: `CLAUDE.md` (update config structure section)
- Modify: `docs/bugs/BUNDLE-01-curriculum-observation-architecture/ENH-28-experiment-level-configuration-hierarchy.md`

**Step 1: Update CLAUDE.md config section**

Find the "Configuration System" section in `CLAUDE.md` and update:

```markdown
## Configuration System

Training controlled via YAML configs in hierarchical v2.1 structure.

### Structure

```
configs/<experiment_name>/
├── experiment.yaml       # Metadata (name, description, author)
├── stratum.yaml          # World shape (substrate type, grid size, temporal)
├── environment.yaml      # Vocabulary (meters, affordances, VFS variables)
├── actions.yaml          # Action space configuration
├── agent.yaml            # Perception + Drive + Brain
└── levels/
    ├── L1_full_observability/
    │   ├── curriculum.yaml   # Vision/temporal activation per level
    │   ├── bars.yaml         # Bar parameters + cascades
    │   ├── affordances.yaml  # Affordance parameters
    │   └── training.yaml     # Runtime orchestration
    └── [other levels]/
```

### Key Principles

**WHAT vs HOW Split**:
- `environment.yaml` defines WHAT exists (vocabulary - breaks checkpoints)
- `levels/*/bars.yaml` defines HOW bars behave (parameters - doesn't break)
- `levels/*/affordances.yaml` defines HOW affordances behave (parameters - doesn't break)

**Support vs Active Pattern**:
- `stratum.yaml` declares which observation fields CAN exist (vision.support, temporal.support)
- `curriculum.yaml` declares which fields ARE active vs masked (active_vision, active_temporal)
- Enables transfer learning: all levels have same obs_dim, different active fields

**No-Defaults Principle**: All behavioral parameters must be explicitly specified.

### Active Curriculum Levels

```bash
# L0_0: Temporal credit assignment (3×3 grid, 1 affordance)
uv run scripts/run_demo.py --config configs/default_curriculum --level L0_0_minimal

# L0_5: Dual resource management (7×7 grid, 4 affordances)
uv run scripts/run_demo.py --config configs/default_curriculum --level L0_5_dual_resource

# L1: Full observability baseline (8×8 grid, 14 affordances)
uv run scripts/run_demo.py --config configs/default_curriculum --level L1_full_observability

# L2: POMDP with 5×5 local window (8×8 grid, 14 affordances)
uv run scripts/run_demo.py --config configs/default_curriculum --level L2_partial_observability

# L3: Temporal mechanics with 24-tick day/night cycle (8×8 grid, 14 affordances)
uv run scripts/run_demo.py --config configs/default_curriculum --level L3_temporal_mechanics
```
```

**Step 2: Update ENH-28 status**

Update `ENH-28-experiment-level-configuration-hierarchy.md`:

```markdown
Severity: medium
Status: implemented  # Changed from design-v2.1-complete

## Status

- **Design v2.1**: COMPLETE (2025-11-15)
- **Implementation**: COMPLETE (2025-11-15)
  - Phase 1: Setup & safety net ✓
  - Phase 2: Model config (L1 reference) ✓
  - Phase 3: DTO creation (6 Pydantic DTOs) ✓
  - Phase 4: Compiler updates ✓
  - Phase 5: Test updates (144 tests passing) ✓
  - Phase 6: Remaining levels (L0_0, L0_5, L2, L3) ✓
  - Phase 7: Cleanup & validation ✓
- **Migration**: All 5 curriculum levels migrated to v2.1
- **Tests**: All 144 tests passing
- **Merged**: [Will be updated after merge]
```

**Step 3: Commit documentation updates**

```bash
git add CLAUDE.md docs/bugs/BUNDLE-01-curriculum-observation-architecture/ENH-28-experiment-level-configuration-hierarchy.md
git commit -m "docs: update for v2.1 config implementation

- CLAUDE.md: document hierarchical structure and usage
- ENH-28: status → implemented, added implementation checklist
- All phases complete, ready for merge"
```

### Task 7.4: Final git log review and cleanup

**Files:**
- None (verification only)

**Step 1: Review commit history**

```bash
git log --oneline feature/config-v2.1 --not main | head -30
```

Expected output: Clean sequence of commits showing progression through phases

**Step 2: Verify feature branch is clean**

```bash
git status
```

Expected output: Clean working directory, all changes committed

**Step 3: Create final Phase 7 completion marker**

```bash
cat >> docs/bugs/BUNDLE-01-curriculum-observation-architecture/implementation-plan.md << 'EOF'

---

## Implementation Status: COMPLETE

**Date Completed**: 2025-11-15

### Phase Completion Summary

- ✅ Phase 1: Setup & Safety Net (4 tasks)
- ✅ Phase 2: Create Model Config (13 tasks)
- ✅ Phase 3: DTO Creation (8 tasks)
- ✅ Phase 4: Compiler Updates (7 tasks)
- ✅ Phase 5: Test Updates (6 tasks)
- ✅ Phase 6: Remaining Levels (5 tasks)
- ✅ Phase 7: Cleanup & Validation (5 tasks)

**Total**: 48 tasks completed

### Deliverables

✅ Hierarchical config structure (9 files per experiment)
✅ 6 new Pydantic DTOs with strict validation
✅ Updated compiler with 7-stage pipeline
✅ Cross-curriculum vocabulary validation enforced
✅ Observation spec with Support/Active pattern
✅ 5 curriculum levels migrated (L0_0, L0_5, L1, L2, L3)
✅ 144 tests passing
✅ Documentation updated
✅ Ready for merge to main

### Validation

- All tests pass: ✅ 144/144
- All levels compile: ✅ L0_0, L0_5, L1, L2, L3
- Smoke tests pass: ✅ All levels run 10 episodes
- No compilation errors: ✅
- No references to old flat structure: ✅
- Documentation updated: ✅

**Status**: Ready to merge to main
EOF

git add docs/bugs/BUNDLE-01-curriculum-observation-architecture/implementation-plan.md
git commit -m "docs: mark Phase 7 and implementation complete

All 7 phases complete:
- 48 tasks executed successfully
- All deliverables achieved
- All validation checks passed
- Ready for merge to main"
```

### Task 7.5: Merge to main

**Files:**
- None (git operations only)

**Step 1: Pre-merge validation**

```bash
# Ensure on feature branch
git branch --show-current

# Verify tests pass one more time
UV_CACHE_DIR=.uv-cache PYTHONPATH=$(pwd)/src uv run pytest tests/test_townlet/ -q --tb=no

# Check for uncommitted changes
git status
```

Expected output: On `feature/config-v2.1`, tests pass, clean status

**Step 2: Merge to main**

```bash
git checkout main
git pull origin main  # Ensure main is up to date

# Merge feature branch (no fast-forward to preserve history)
git merge feature/config-v2.1 --no-ff -m "feat: implement config v2.1 hierarchical structure (ENH-28)

BREAKING CHANGE: Config structure changed from flat to hierarchical

Old structure (v1):
  configs/L1_full_observability/
  ├── substrate.yaml
  ├── bars.yaml
  ├── affordances.yaml
  ├── training.yaml
  └── ... (8 flat files)

New structure (v2.1):
  configs/default_curriculum/
  ├── experiment.yaml       # Metadata
  ├── stratum.yaml          # World shape
  ├── environment.yaml      # Vocabulary (bars, affordances, VFS)
  ├── actions.yaml          # Action space
  ├── agent.yaml            # Perception + Drive + Brain
  └── levels/
      └── L1_full_observability/
          ├── curriculum.yaml   # Vision/temporal activation
          ├── bars.yaml         # Bar parameters
          ├── affordances.yaml  # Affordance parameters
          └── training.yaml     # Runtime orchestration

Benefits:
- Cross-curriculum vocabulary consistency enforced
- Support/Active pattern enables transfer learning (same obs_dim)
- WHAT vs HOW split (vocabulary breaks checkpoints, parameters don't)
- Normalized vision_range (0.0-1.0 float)
- No-defaults principle enforced throughout

Implementation (7 phases, 48 tasks):
- Phase 1: Setup & safety net (branch, archive, baseline)
- Phase 2: Model config (L1 reference, 9 YAML files)
- Phase 3: DTO creation (6 Pydantic DTOs with validation)
- Phase 4: Compiler updates (7-stage pipeline)
- Phase 5: Test updates (144 tests passing)
- Phase 6: Remaining levels (L0_0, L0_5, L2, L3)
- Phase 7: Cleanup & validation (docs, merge)

All 5 curriculum levels migrated:
- L0_0_minimal: Temporal credit assignment (1 bar, 1 affordance)
- L0_5_dual_resource: Cascade effects (2 bars, 4 affordances)
- L1_full_observability: Baseline (8 bars, 14 affordances)
- L2_partial_observability: POMDP (5×5 window, 8 bars, 14 affordances)
- L3_temporal_mechanics: Day/night cycle (8 bars, 14 affordances)

Documentation:
- See docs/bugs/BUNDLE-01-curriculum-observation-architecture/ for complete design
- See docs/plans/2025-11-15-config-v2.1-* for detailed implementation plans

Closes ENH-28"
```

**Step 3: Verify merge successful**

```bash
# Verify on main
git branch --show-current

# Verify tests still pass
UV_CACHE_DIR=.uv-cache PYTHONPATH=$(pwd)/src uv run pytest tests/test_townlet/ -q --tb=no

# Show merge commit
git log -1 --stat
```

Expected output: On `main`, tests pass, merge commit shows all changes

**Step 4: Push to remote (if applicable)**

```bash
# Push main branch
git push origin main

# Delete feature branch locally
git branch -d feature/config-v2.1

# Delete feature branch remotely (if pushed)
# git push origin --delete feature/config-v2.1
```

**Step 5: Celebrate! 🎉**

```bash
echo "🎉 Config v2.1 Implementation Complete! 🎉"
echo ""
echo "Summary:"
echo "- 7 phases completed"
echo "- 48 tasks executed"
echo "- 5 curriculum levels migrated to v2.1"
echo "- 144 tests passing"
echo "- Hierarchical structure enforcing cross-curriculum consistency"
echo "- Support/Active pattern enabling transfer learning"
echo "- Clean git history with documented implementation phases"
echo ""
echo "Next steps:"
echo "- Run full training on all levels to verify behavior unchanged"
echo "- Monitor for any runtime issues with new structure"
echo "- Consider power user optimization modes (future enhancement)"
echo ""
echo "Well done! 🚀"
```

**Phase 7 Complete!** Config v2.1 implemented and merged to main. 🎉

---

## Summary

**Total Time**: ~8-10 hours (depending on test complexity and unexpected issues)

**Phases Completed**:
1. ✅ Setup & Safety Net (30 min) - 4 tasks
2. ✅ Create Model Config (1 hour) - 13 tasks
3. ✅ DTO Creation (2-3 hours) - 8 tasks
4. ✅ Compiler Updates (2-3 hours) - 7 tasks
5. ✅ Test Updates (2-3 hours) - 6 tasks
6. ✅ Remaining Levels (1-2 hours) - 5 tasks
7. ✅ Cleanup & Validation (30 min) - 5 tasks

**Total Tasks**: 48 bite-sized tasks (2-5 minutes each)

**Key Deliverables**:
- ✅ Hierarchical config structure (experiment + stratum + environment + agent + curriculum)
- ✅ 6 new Pydantic DTOs with strict validation
- ✅ Updated compiler with cross-curriculum vocabulary validation
- ✅ Observation spec with Support/Active pattern
- ✅ 5 curriculum levels migrated (L0_0, L0_5, L1, L2, L3)
- ✅ 144 tests passing
- ✅ Complete documentation and clean git history

**Key Patterns Applied**:
- **Support vs Active**: Experiment declares fields that CAN exist, curriculum declares which ARE active
- **WHAT vs HOW**: Vocabulary breaks checkpoints, parameters don't
- **No-defaults principle**: All settings mandatory
- **Test-driven validation**: Let failures guide fixes
- **Clean-break migration**: No backwards compatibility needed (zero users)

**Success Metrics**:
- ✅ All 144 tests pass
- ✅ All 5 levels compile successfully
- ✅ obs_dim consistent across curriculum (enables transfer learning)
- ✅ No old config references remain
- ✅ Clean git history with documented phases
- ✅ Merged to main without conflicts

---

**Implementation Notes**:

This plan assumes:
- You're working in the feature branch created in Phase 1
- Pydantic DTOs from Phase 3 are working
- ObservationSpec and ObservationField classes exist in VFS module
- BarsConfig, AffordancesConfig, TrainingConfig DTOs already exist

Adjust task details based on your actual codebase structure.
